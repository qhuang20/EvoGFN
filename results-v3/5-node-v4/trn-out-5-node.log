Partial Empirical Reward Distribution: {2.5e-05: 1.0}
Agent checkpoint saved at iteration 0 in 5.
Model checkpoint saved at iteration 0 in 5.
Partial Empirical Reward Distribution: {2.5e-05: 0.9294554455445545, 30: 0.06806930693069307, 300: 0.0024752475247524753}
Partial Empirical Reward Distribution: {2.5e-05: 0.9129353233830846, 30: 0.08084577114427861, 300: 0.006218905472636816}
Partial Empirical Reward Distribution: {2.5e-05: 0.9223421926910299, 30: 0.07350498338870431, 300: 0.004152823920265781}
Partial Empirical Reward Distribution: {2.5e-05: 0.9389027431421446, 30: 0.05798004987531172, 300: 0.003117206982543641}
Partial Empirical Reward Distribution: {2.5e-05: 0.9500998003992016, 30: 0.04740518962075848, 300: 0.00249500998003992}
Partial Empirical Reward Distribution: {2.5e-05: 0.9575707154742097, 30: 0.040349417637271213, 300: 0.0020798668885191347}
Partial Empirical Reward Distribution: {2.5e-05: 0.9609486447931527, 30: 0.037268188302425106, 300: 0.001783166904422254}
Partial Empirical Reward Distribution: {2.5e-05: 0.958645443196005, 30: 0.039794007490636704, 300: 0.001560549313358302}
Partial Empirical Reward Distribution: {2.5e-05: 0.9558823529411765, 30: 0.042591564927857935, 300: 0.0013873473917869034, 3000: 0.00013873473917869035}
Partial Empirical Reward Distribution: {2.5e-05: 0.9425574425574426, 30: 0.05544455544455545, 300: 0.0018731268731268732, 3000: 0.00012487512487512488}
Agent checkpoint saved at iteration 1000 in 5.
Model checkpoint saved at iteration 1000 in 5.
Partial Empirical Reward Distribution: {2.5e-05: 0.9473206176203451, 30: 0.05086285195277021, 300: 0.0017029972752043597, 3000: 0.00011353315168029064}
Partial Empirical Reward Distribution: {2.5e-05: 0.951706910907577, 30: 0.0466278101582015, 300: 0.0015611990008326394, 3000: 0.00010407993338884263}
Partial Empirical Reward Distribution: {2.5e-05: 0.955130668716372, 30: 0.04313989239046887, 300: 0.0016333589546502691, 3000: 9.607993850883935e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9582441113490364, 30: 0.04006067094932191, 300: 0.0016059957173447537, 3000: 8.922198429693076e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9610259826782145, 30: 0.03739173884077282, 300: 0.0014990006662225182, 3000: 8.327781479013991e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9634603372891942, 30: 0.03505621486570893, 300: 0.0014053716427232979, 3000: 7.807620237351655e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9655349794238683, 30: 0.03306878306878307, 300: 0.0013227513227513227, 3000: 7.348618459729571e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9674486396446419, 30: 0.031232648528595225, 300: 0.001249305941143809, 3000: 6.94058856191005e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9691609679116254, 30: 0.02958968963703314, 300: 0.0011835875854813256, 3000: 6.575486586007364e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9707021489255372, 30: 0.02811094452773613, 300: 0.0011244377811094452, 3000: 6.24687656171914e-05}
Agent checkpoint saved at iteration 2000 in 5.
Model checkpoint saved at iteration 2000 in 5.
Partial Empirical Reward Distribution: {2.5e-05: 0.9720966206568301, 30: 0.026772965254640648, 300: 0.001070918610185626, 3000: 5.949547834364588e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9733643798273512, 30: 0.025556565197637438, 300: 0.0010222626079054976, 3000: 5.679236710586097e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9744676227727075, 30: 0.024500217296827467, 300: 0.0009778357235984355, 3000: 5.432420686657975e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9755310287380258, 30: 0.023479800083298627, 300: 0.000937109537692628, 3000: 5.2061640982923784e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9765093962415033, 30: 0.022540983606557378, 300: 0.000899640143942423, 3000: 4.998000799680128e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9774125336409073, 30: 0.02167435601691657, 300: 0.0008650519031141869, 3000: 4.805843906189927e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9782487967419474, 30: 0.02087189929655683, 300: 0.0008330248056275454, 3000: 4.6279155868196966e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9790253480899679, 30: 0.020126740449839343, 300: 0.0008032845412352731, 3000: 4.4626918957515175e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9797483626335747, 30: 0.01943295415374009, 300: 0.0007755946225439503, 3000: 4.3088590141330577e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9804231922692436, 30: 0.018785404865044986, 300: 0.0007497500833055648, 3000: 4.165278240586471e-05}
Agent checkpoint saved at iteration 3000 in 5.
Model checkpoint saved at iteration 3000 in 5.
Partial Empirical Reward Distribution: {2.5e-05: 0.9810544985488552, 30: 0.018179619477587877, 300: 0.0007255723960012899, 3000: 4.0309577555627215e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9816463605123399, 30: 0.01761168384879725, 300: 0.0007029053420805998, 3000: 3.9050296782255544e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9821644956073917, 30: 0.017116025446834292, 300: 0.0006816116328385338, 3000: 3.78673129354741e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9824683916495148, 30: 0.016796530432225815, 300: 0.0006983240223463687, 3000: 3.675389591296677e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9829691516709511, 30: 0.0163167666381034, 300: 0.000678377606398172, 3000: 3.570408454727221e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9834420994168287, 30: 0.01586364898639267, 300: 0.000659539016939739, 3000: 3.471257983893363e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9838894893272089, 30: 0.01543501756282086, 300: 0.0006417184544717644, 3000: 3.377465549851391e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9843133385951065, 30: 0.015028939752696658, 300: 0.0006248355695869508, 3000: 3.288608260983952e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9847154575749808, 30: 0.014643681107408357, 300: 0.0006088182517303255, 3000: 3.204306588054345e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9850974756310922, 30: 0.014277680579855036, 300: 0.0005936015996001, 3000: 3.124218945263684e-05}
Agent checkpoint saved at iteration 4000 in 5.
Model checkpoint saved at iteration 4000 in 5.
Partial Empirical Reward Distribution: {2.5e-05: 0.9854608632040965, 30: 0.013929529383077299, 300: 0.000579127042184833, 3000: 3.0480370641307e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9858069507260177, 30: 0.013597952868364675, 300: 0.0005653415853368246, 3000: 2.9754820280885503e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9861369448965357, 30: 0.0132817949314113, 300: 0.0005521971634503604, 3000: 2.9063008602650547e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9864519427402862, 30: 0.012980004544421723, 300: 0.0005396500795273801, 3000: 2.8402635764598956e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9866696289713397, 30: 0.012774938902466119, 300: 0.0005276605198844701, 3000: 2.7771606309708954e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9869050206476853, 30: 0.012551619213214519, 300: 0.0005161921321451858, 3000: 2.716800695500978e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9871835779621357, 30: 0.012284620293554562, 300: 0.0005052116570942352, 3000: 2.6590087215486065e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.987450531139346, 30: 0.012028744011664236, 300: 0.0004946886065403041, 3000: 2.603624244948969e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9877065904917364, 30: 0.011783309528667619, 300: 0.0004845949806162008, 3000: 2.550499897980004e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9879524095180964, 30: 0.01154769046190762, 300: 0.00047490501899620074, 3000: 2.499500099980004e-05}
Agent checkpoint saved at iteration 5000 in 5.
Model checkpoint saved at iteration 5000 in 5.
Partial Empirical Reward Distribution: {2.5e-05: 0.9881885904724563, 30: 0.011321309547147619, 300: 0.00046559498137620074, 3000: 2.450499901980004e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.988415689290521, 30: 0.01110363391655451, 300: 0.00045664295327821575, 3000: 2.403383964622188e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9886342199584984, 30: 0.01089417091114884, 300: 0.00044802867383512545, 3000: 2.358045651763818e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9888446583965932, 30: 0.010692464358452138, 300: 0.00043973338270690614, 3000: 2.3143862247731902e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9889338302126885, 30: 0.010611706962370479, 300: 0.00043173968369387386, 3000: 2.272314124704599e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9886627387966435, 30: 0.010779325120514193, 300: 0.0005133011962149616, 3000: 4.463488662738796e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9878530082441677, 30: 0.011401508507279424, 300: 0.0006577793369584283, 3000: 8.770391159445712e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9880624030339596, 30: 0.011204964661265299, 300: 0.0006464402689191519, 3000: 8.619203585588692e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9882647008981529, 30: 0.011015082189459414, 300: 0.0006354855109303507, 3000: 8.47314014573801e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.988460256623896, 30: 0.010831528078653558, 300: 0.0006248958506915514, 3000: 8.331944675887353e-05}
Agent checkpoint saved at iteration 6000 in 5.
Model checkpoint saved at iteration 6000 in 5.
Partial Empirical Reward Distribution: {2.5e-05: 0.9886494017374201, 30: 0.010653991148991968, 300: 0.0006146533355187674, 3000: 8.195377806916898e-05}
Partial Empirical Reward Distribution: {2.5e-05: 0.9888122883405902, 30: 0.010502338332527011, 300: 0.0006047411707789066, 3000: 8.063215610385422e-05}
