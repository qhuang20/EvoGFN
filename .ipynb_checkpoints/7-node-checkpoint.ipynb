{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import gzip\n",
    "import heapq\n",
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from itertools import count\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dev = [torch.device('cpu')]\n",
    "# tf = lambda x: torch.FloatTensor(x).to(_dev[0])\n",
    "# tl = lambda x: torch.LongTensor(x).to(_dev[0])\n",
    "tf = lambda x: torch.FloatTensor(np.array(x)).to(_dev[0])  # Convert to numpy array first\n",
    "tl = lambda x: torch.LongTensor(np.array(x)).to(_dev[0])\n",
    "\n",
    "def set_device(dev):\n",
    "    _dev[0] = dev \n",
    "\n",
    "def func_corners(x):\n",
    "    ax = abs(x)\n",
    "    return (ax > 0.5).prod(-1) * 0.5 + ((ax < 0.8) * (ax > 0.6)).prod(-1) * 2 + 1e-1\n",
    "\n",
    "\n",
    "\n",
    "# Define the sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Define the dynamical system for the n-node system with sigmoid\n",
    "def node_system_with_sigmoid(x, t, coord):\n",
    "    matrix_dim = len(x)\n",
    "    M_tilde = np.reshape(coord, (matrix_dim, matrix_dim))\n",
    "    z = M_tilde.dot(x)  # Compute M_tilde * x\n",
    "    sigmoid_z = sigmoid(z)\n",
    "    dxdt = sigmoid_z - x  # Compute the derivative   \n",
    "    return dxdt\n",
    "\n",
    "# Calculate reward given the weights\n",
    "def reward_oscillator(coord, ndim):\n",
    "    delta = 0.0001  # 0.0001\n",
    "    matrix_dim = int(np.sqrt(ndim))\n",
    "    x0 = np.linspace(0, 1, matrix_dim, endpoint=False)  # Initial conditions\n",
    "    t = np.linspace(0, 20, 200)  # Define the time points\n",
    "    sol = odeint(node_system_with_sigmoid, x0, t, args=(coord, ))\n",
    "    \n",
    "    # Calculate the total number of sharp peaks across all time series\n",
    "    total_peaks = 0\n",
    "    for i in range(matrix_dim):  # Loop through each time series x1, x2, ..., xn\n",
    "        x_i = sol[:, i]\n",
    "        dx_i = np.diff(x_i)  # First derivative approximation\n",
    "        peaks = 0\n",
    "        for j in range(1, len(dx_i)):\n",
    "            if dx_i[j-1] > 0 and dx_i[j] < 0:  # Detect a peak\n",
    "                sharpness = x_i[j] - (x_i[j-1] + x_i[j+1]) / 2\n",
    "                if sharpness > delta:  # Check if the peak is sharp\n",
    "                    peaks += 1\n",
    "        total_peaks += peaks  # Add the number of sharp peaks for this time series\n",
    "    \n",
    "    if total_peaks == 0:\n",
    "        return 2.5e-5  # see log_reg_c\n",
    "    else:\n",
    "        return total_peaks  # number of peaks   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GridEnv:\n",
    "\n",
    "    def __init__(self, horizon, ndim=2, func=None):\n",
    "        self.horizon = horizon\n",
    "        self.ndim = ndim\n",
    "        self.func = func   # Sets the reward function.\n",
    "        self._true_density = None\n",
    " \n",
    "    def obs(self, s=None):\n",
    "        \"\"\"\n",
    "        Returns a one-hot encoded observation of the current state.\n",
    "        The observation is a flattened vector representing the agent's position in the grid.\n",
    "        \"\"\"\n",
    "        s = np.int32(self._state if s is None else s)\n",
    "        z = np.zeros((self.horizon * self.ndim), dtype=np.float32)\n",
    "        z[np.arange(len(s)) * self.horizon + s] = 1 \n",
    "        return z    # one-hot agent's current position in the grid.\n",
    "    \n",
    "    def s2x(self, s):\n",
    "        \"\"\"\n",
    "        Transform the grid of indices (state s) to spherical coordinates and then calculate the cartesian coordinates\n",
    "        (x_1, x_2, ..., x_n) for n dimensions.\n",
    "        \n",
    "        s[0]: radial distance (r)\n",
    "        s[1:n-1]: polar angles (theta_1, theta_2, ..., theta_{n-2})\n",
    "        s[n-1]: azimuthal angle (phi)\n",
    "        \"\"\"\n",
    "        # Initialize the radius (r) from the first component of the state vector\n",
    "        r = s[0]\n",
    "    \n",
    "        # Initialize an array to hold the Cartesian coordinates\n",
    "        x = np.zeros(self.ndim)\n",
    "    \n",
    "        # Constants or parameters (assuming self.horizon refers to the number of steps in the grid)\n",
    "        horizon = self.horizon\n",
    "        \n",
    "        # Calculate the spherical to Cartesian conversion\n",
    "        product = r\n",
    "        for i in range(1, self.ndim):\n",
    "            if i == self.ndim - 1:\n",
    "                # The last angle (phi) ranges from 0 to 2π\n",
    "                phi = s[i] * 2 * np.pi / horizon\n",
    "                x[i - 1] = product * np.cos(phi)\n",
    "                x[i] = product * np.sin(phi)\n",
    "            else:\n",
    "                # The other angles (theta) range from 0 to π\n",
    "                theta = s[i] * np.pi / horizon\n",
    "                x[i - 1] = product * np.sin(theta)\n",
    "                product *= np.cos(theta)\n",
    "    \n",
    "        return x\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the environment to the initial state.\n",
    "        \"\"\"\n",
    "        self._state = np.int32([0] * self.ndim)   # start position (0,0...)\n",
    "        self._step = 0\n",
    "        return self.obs(), self.func(self.s2x(self._state), self.ndim), self._state\n",
    "\n",
    "    def parent_transitions(self, s, used_stop_action):\n",
    "        \"\"\"\n",
    "        Determines the parent states and corresponding actions that could have led to the current state.\n",
    "        \n",
    "        Parameters:\n",
    "        - s: The current state.\n",
    "        - used_stop_action: A boolean indicating if the stop action was used.\n",
    "        \n",
    "        Returns:\n",
    "        - A list of possible parent states (one-hot encoded).\n",
    "        - A list of corresponding actions.\n",
    "        \"\"\"\n",
    "        if used_stop_action:\n",
    "            return [self.obs(s)], [self.ndim]\n",
    "            \n",
    "        parents = []\n",
    "        actions = []\n",
    "        for i in range(self.ndim):\n",
    "            if s[i] > 0:\n",
    "                sp = s.copy()  # s + 0\n",
    "                sp[i] -= 1\n",
    "                if sp.max() == self.horizon - 1:  # Can't have a terminal parent\n",
    "                    continue\n",
    "                parents.append(self.obs(sp))  # Generate observation for parent state\n",
    "                actions.append(i)\n",
    "        return parents, actions\n",
    "\n",
    "    \n",
    "    def step(self, a):\n",
    "        \"\"\"\n",
    "        Updates the environment's state based on the action `a` and \n",
    "        returns the new observation, reward, done signal, and new state.\n",
    "        \"\"\"\n",
    "        s = self._state.copy()\n",
    "        if a < self.ndim:\n",
    "            s[a] += 1\n",
    "        \n",
    "        done = s.max() >= self.horizon - 1 or a == self.ndim\n",
    "        self._state = s  # Update the internal state\n",
    "        self._step += 1  # Increment step counter\n",
    "        \n",
    "        return self.obs(), 0 if not done else self.func(self.s2x(s), self.ndim), done, s\n",
    "\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, args, env):\n",
    "        self.buf = []\n",
    "        self.strat = args.replay_strategy\n",
    "        self.sample_size = args.replay_sample_size\n",
    "        self.bufsize = args.replay_buf_size\n",
    "        self.env = env\n",
    "\n",
    "    def add(self, x, r_x):\n",
    "        if self.strat == 'top_k':\n",
    "            if len(self.buf) < self.bufsize or r_x > self.buf[0][0]:\n",
    "                self.buf = sorted(self.buf + [(r_x, x)])[-self.bufsize:]\n",
    "\n",
    "    def sample(self):\n",
    "        if not len(self.buf):\n",
    "            return []\n",
    "        idxs = np.random.randint(0, len(self.buf), self.sample_size)\n",
    "        return sum([self.generate_backward(*self.buf[i]) for i in idxs], [])  # Samples from the buffer and generates trajectories backward.\n",
    "\n",
    "    def generate_backward(self, r, s0):\n",
    "        s = np.int8(s0)\n",
    "        os0 = self.env.obs(s)\n",
    "        # If s0 is a forced-terminal state, the the action that leads\n",
    "        # to it is s0.argmax() which .parents finds, but if it isn't,\n",
    "        # we must indicate that the agent ended the trajectory with\n",
    "        # the stop action\n",
    "        used_stop_action = s.max() < self.env.horizon - 1\n",
    "        done = True\n",
    "        # Now we work backward from that last transition\n",
    "        traj = []\n",
    "        while s.sum() > 0:\n",
    "            parents, actions = self.env.parent_transitions(s, used_stop_action)\n",
    "            # add the transition\n",
    "            traj.append([tf(i) for i in (parents, actions, [r], [self.env.obs(s)], [done])])\n",
    "            # Then randomly choose a parent state\n",
    "            if not used_stop_action:\n",
    "                i = np.random.randint(0, len(parents))\n",
    "                a = actions[i]\n",
    "                s[a] -= 1\n",
    "            # Values for intermediary trajectory states:\n",
    "            used_stop_action = False\n",
    "            done = False\n",
    "            r = 0\n",
    "        return traj  # Generates a trajectory by working backward from a terminal state.\n",
    "\n",
    "def make_mlp(l, act=nn.LeakyReLU(), tail=[]):\n",
    "    return nn.Sequential(*(sum(\n",
    "        [[nn.Linear(i, o)] + ([act] if n < len(l)-2 else [])\n",
    "         for n, (i, o) in enumerate(zip(l, l[1:]))], []) + tail))\n",
    "    \n",
    "class FlowNetAgent:\n",
    "    def __init__(self, args, envs):\n",
    "        self.model = make_mlp([args.horizon * args.ndim] +\n",
    "                              [args.n_hid] * args.n_layers +\n",
    "                              [args.ndim+1])\n",
    "        self.model.to(args.dev)\n",
    "        self.target = copy.deepcopy(self.model)\n",
    "        self.envs = envs\n",
    "        self.ndim = args.ndim\n",
    "        self.tau = args.bootstrap_tau\n",
    "        self.replay = ReplayBuffer(args, envs[0])\n",
    "        self.log_reg_c = args.log_reg_c\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.model.parameters()\n",
    "\n",
    "    def sample_many(self, mbsize, all_visited_done):\n",
    "        \"\"\"Collects transition data from multiple parallel trajectories.\"\"\"\n",
    "        batch = []  # store transitions.\n",
    "        batch += self.replay.sample()\n",
    "        s = tf([i.reset()[0] for i in self.envs])\n",
    "        done = [False] * mbsize\n",
    "        while not all(done):\n",
    "            # Note to self: this is ugly, ugly code\n",
    "            with torch.no_grad():\n",
    "                acts = Categorical(logits=self.model(s)).sample()   # Samples actions based on model's logits.\n",
    "            step = [i.step(a) for i,a in zip([e for d, e in zip(done, self.envs) if not d], acts)]\n",
    "            p_a = [self.envs[0].parent_transitions(sp_state, a == self.ndim)\n",
    "                   for a, (sp, r, done, sp_state) in zip(acts, step)]\n",
    "            batch += [[tf(i) for i in (p, a, [r], [sp], [d])]\n",
    "                      for (p, a), (sp, r, d, _) in zip(p_a, step)]\n",
    "            c = count(0)\n",
    "            m = {j:next(c) for j in range(mbsize) if not done[j]}\n",
    "            done = [bool(d or step[m[i]][2]) for i, d in enumerate(done)]\n",
    "            s = tf([i[0] for i in step if not i[2]])\n",
    "            for (_, r, d, sp) in step:\n",
    "                if d:\n",
    "                    all_visited_done.append((tuple(sp), r))  # (state, reward) pairs\n",
    "                    self.replay.add(tuple(sp), r) \n",
    "        return batch  # it returns a batch of collected transitions for training. {parents, actions, reward, next_state, done}\n",
    "\n",
    "    def sample_one_traj(self):\n",
    "        \"\"\"\n",
    "        Samples a single trajectory and returns it.\n",
    "        \"\"\"\n",
    "        traj = []\n",
    "        env = self.envs[0]\n",
    "        traj.append([[], [], 0, np.int32([0] * self.ndim), False])\n",
    "        \n",
    "        s = tf(env.reset()[0])\n",
    "        done = False\n",
    "        while not done:\n",
    "            with torch.no_grad():\n",
    "                logits = self.model(s.unsqueeze(0))\n",
    "                action_dist = Categorical(logits=logits)\n",
    "                a = action_dist.sample().item()\n",
    "            sp, r, done_flag, sp_state = env.step(a)\n",
    "            parent_states, parent_actions = env.parent_transitions(sp_state, a == self.ndim)\n",
    "            traj.append([parent_states, parent_actions, r, sp_state, done_flag])\n",
    "            \n",
    "            s = tf(sp)\n",
    "            done = done_flag\n",
    "        return traj\n",
    "\n",
    "    def learn_from(self, it, batch):\n",
    "        loginf = tf([1000])\n",
    "        batch_idxs = tl(sum([[i]*len(parents) for i, (parents,_,_,_,_) in enumerate(batch)], []))\n",
    "        parents, actions, r, sp, done = map(torch.cat, zip(*batch))\n",
    "        parents_Qsa = self.model(parents)[torch.arange(parents.shape[0]), actions.long()]\n",
    "        in_flow = torch.log(self.log_reg_c + torch.zeros((sp.shape[0],))\n",
    "                            .index_add_(0, batch_idxs, torch.exp(parents_Qsa)))\n",
    "        if self.tau > 0:\n",
    "            with torch.no_grad(): next_q = self.target(sp)\n",
    "        else:\n",
    "            next_q = self.model(sp)\n",
    "        next_qd = next_q * (1-done).unsqueeze(1) + done.unsqueeze(1) * (-loginf)\n",
    "        out_flow = torch.logsumexp(torch.cat([torch.log(self.log_reg_c + r)[:, None], next_qd], 1), 1)\n",
    "        \n",
    "        term_loss = ((in_flow - out_flow) * done).pow(2).sum() / (done.sum() + 1e-20)\n",
    "        flow_loss = ((in_flow - out_flow) * (1-done)).pow(2).sum() / ((1-done).sum() + 1e-20)\n",
    "        \n",
    "        # loss = (in_flow - out_flow).pow(2).mean()\n",
    "        leaf_coef = 10\n",
    "        loss = term_loss * leaf_coef + flow_loss\n",
    "\n",
    "        if self.tau > 0:\n",
    "            for a,b in zip(self.model.parameters(), self.target.parameters()):\n",
    "                b.data.mul_(1-self.tau).add_(self.tau*a)\n",
    "\n",
    "        return loss, term_loss, flow_loss    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training \n",
    "\n",
    "def make_opt(params, args):\n",
    "    params = list(params)\n",
    "    if not len(params):\n",
    "        return None\n",
    "    if args.opt == 'adam':\n",
    "        opt = torch.optim.Adam(params, args.learning_rate,\n",
    "                               betas=(args.adam_beta1, args.adam_beta2))\n",
    "    elif args.opt == 'msgd':\n",
    "        opt = torch.optim.SGD(params, args.learning_rate, momentum=args.momentum)\n",
    "    return opt\n",
    "\n",
    "def compute_empirical_reward_distribution(visited):\n",
    "    if not len(visited):\n",
    "        return {}\n",
    "    reward_hist = defaultdict(int)\n",
    "    for _, reward in visited:\n",
    "        reward_hist[reward] += 1\n",
    "    total_visits = sum(reward_hist.values())\n",
    "    empirical_distribution = {reward: count / total_visits for reward, count in reward_hist.items()}\n",
    "    return empirical_distribution\n",
    "\n",
    "\n",
    "\n",
    "all_losses = []\n",
    "all_visited_done = []\n",
    "\n",
    "def main(args):\n",
    "    args.dev = torch.device(args.device)\n",
    "    set_device(args.dev)\n",
    "    f = {'default': None,\n",
    "         'corners': func_corners,\n",
    "         'oscillator': reward_oscillator,\n",
    "    }[args.func]\n",
    "    \n",
    "    env = GridEnv(args.horizon, args.ndim, func=f)\n",
    "    envs = [GridEnv(args.horizon, args.ndim, func=f)\n",
    "            for i in range(args.mbsize)] \n",
    "    ndim = args.ndim\n",
    "    nnode = args.nnode\n",
    "\n",
    "    if args.method == 'flownet':\n",
    "        agent = FlowNetAgent(args, envs)\n",
    "    elif args.method == 'mcmc':\n",
    "        agent = MHAgent(args, envs)\n",
    "    elif args.method == 'random_traj':\n",
    "        agent = RandomTrajAgent(args, envs)\n",
    "\n",
    "    opt = make_opt(agent.parameters(), args)\n",
    "\n",
    "        \n",
    "    \n",
    "    # Log file setup\n",
    "    log_file_path = os.path.join(args.save_path, f'trn-out-{args.nnode}-node.log')\n",
    "    os.makedirs(os.path.dirname(log_file_path), exist_ok=True)\n",
    "    with open(log_file_path, 'w') as log_file:\n",
    "    \n",
    "        # Training Loop Setup\n",
    "        \n",
    "        ttsr = max(int(args.train_to_sample_ratio), 1) # train to sample ratio\n",
    "        sttr = max(int(1/args.train_to_sample_ratio), 1) # sample to train ratio\n",
    "        \n",
    "        for i in tqdm(range(args.n_train_steps+1), disable=not args.progress):\n",
    "            data = []  # a list of transitions from a batch of trajectories\n",
    "            for j in range(sttr):\n",
    "                \"\"\"Agent samples trajectories for training.\"\"\"\n",
    "                data += agent.sample_many(args.mbsize, all_visited_done)   \n",
    "            for j in range(ttsr):\n",
    "                \"\"\"Agent updates its model using the sampled data.\"\"\"\n",
    "                losses = agent.learn_from(i * ttsr + j, data) # returns (opt loss, *metrics)\n",
    "                if losses is not None:\n",
    "                    losses[0].backward(retain_graph=(not i % 50))\n",
    "                    if args.clip_grad_norm > 0:\n",
    "                        torch.nn.utils.clip_grad_norm_(agent.parameters(),\n",
    "                                                       args.clip_grad_norm)\n",
    "                    opt.step()\n",
    "                    opt.zero_grad()\n",
    "                    all_losses.append([i.item() for i in losses])\n",
    "        \n",
    "            # Log empirical reward every 100 iterations\n",
    "            if not i % 100:\n",
    "                empirical_distribution = compute_empirical_reward_distribution(all_visited_done[-args.num_empirical_loss:])\n",
    "                print('Empirical Reward Distribution:', empirical_distribution)\n",
    "                log_file.write(f'Empirical Reward Distribution: {empirical_distribution}\\n')\n",
    "                log_file.flush()  # Ensure data is written to the log file\n",
    "                        \n",
    "            # Save the agent and model every 1000 iterations\n",
    "            if not i % 1000:\n",
    "                root = os.path.join(args.save_path, f\"{nnode}-node\")  # Create the directory for the specific model variation\n",
    "                os.makedirs(root, exist_ok=True)  # Ensure the directory exists\n",
    "            \n",
    "                # Save the entire agent\n",
    "                agent_save_path = os.path.join(root, f\"agent_checkpoint_{i}.pkl.gz\")  # Save agent checkpoint with iteration number\n",
    "                with gzip.open(agent_save_path, 'wb') as f:  # Use gzip for compression\n",
    "                    pickle.dump(agent, f)\n",
    "                print(f\"Agent checkpoint saved at iteration {i} in {nnode}.\")\n",
    "            \n",
    "                # Save the agent's model separately\n",
    "                model_save_path = os.path.join(root, f\"model_checkpoint_{i}.pkl.gz\")  # Save model checkpoint with iteration number\n",
    "                with gzip.open(model_save_path, 'wb') as f:  # Use gzip for compression\n",
    "                    pickle.dump(agent.model, f)\n",
    "                print(f\"Model checkpoint saved at iteration {i} in {nnode}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/30001 [00:00<7:21:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 1.0}\n",
      "Agent checkpoint saved at iteration 0 in 5.\n",
      "Model checkpoint saved at iteration 0 in 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 26/30001 [00:36<14:32:21,  1.75s/it]/tmp/ipykernel_1447826/1931482528.py:2: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  tf = lambda x: torch.FloatTensor(x).to(_dev[0])\n",
      "  0%|          | 101/30001 [01:22<3:25:33,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.901299504950495, 30: 0.09096534653465346, 300: 0.007735148514851485}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 201/30001 [02:06<3:46:56,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.9331467661691543, 30: 0.06296641791044776, 300: 0.00388681592039801}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 301/30001 [02:58<4:30:59,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.9527616279069767, 30: 0.044642857142857144, 300: 0.002595514950166113}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 401/30001 [03:57<5:51:25,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.9577618453865336, 30: 0.03943266832917706, 300: 0.002727556109725686, 3000: 7.793017456359102e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 501/30001 [05:08<6:30:40,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.9474800399201597, 30: 0.04653193612774451, 300: 0.005114770459081836, 3000: 0.000810878243512974, 30000: 6.2375249500998e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 601/30001 [06:25<5:46:38,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.9210690515806988, 30: 0.06213602329450915, 300: 0.014403078202995008, 3000: 0.001975873544093178, 30000: 0.00041597337770382697}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 701/30001 [07:46<7:08:56,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.8918955064194009, 30: 0.075561697574893, 300: 0.026078815977175464, 3000: 0.005572396576319544, 30000: 0.000891583452211127}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 801/30001 [09:16<7:31:17,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.8604868913857678, 30: 0.08926342072409488, 300: 0.0385065543071161, 3000: 0.009909488139825218, 30000: 0.0017556179775280898, 300000: 7.802746566791511e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 901/30001 [10:49<7:55:51,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.8356687014428413, 30: 0.09919533851276359, 300: 0.04789816870144284, 3000: 0.014636514983351832, 30000: 0.0024972253052164264, 300000: 0.00010405105438401775}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1001/30001 [12:29<8:00:18,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.8066308691308691, 30: 0.10932817182817182, 300: 0.0588474025974026, 3000: 0.02104145854145854, 30000: 0.004027222777222777, 300000: 0.00012487512487512488}\n",
      "Agent checkpoint saved at iteration 1000 in 5.\n",
      "Model checkpoint saved at iteration 1000 in 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 1101/30001 [14:16<8:23:16,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.7784116712079927, 30: 0.1185569936421435, 300: 0.06959582198001817, 3000: 0.027247956403269755, 30000: 0.005875340599455041, 300000: 0.0003122161671207993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1201/30001 [16:02<8:25:50,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.7546835970024979, 30: 0.12539029975020816, 300: 0.07881452955870108, 3000: 0.0332014987510408, 30000: 0.007389675270607827, 300000: 0.0005203996669442131}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1301/30001 [17:53<9:05:42,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.7294629131437356, 30: 0.1308608762490392, 300: 0.08906610299769409, 3000: 0.04025749423520369, 30000: 0.009559953881629515, 300000: 0.0007926594926979247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1401/30001 [19:58<10:49:46,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.7063035331905781, 30: 0.13597430406852248, 300: 0.09734118486795146, 3000: 0.04751070663811563, 30000: 0.011844218415417558, 300000: 0.0010260528194147038}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1501/30001 [22:10<9:58:57,  1.26s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6846477348434377, 30: 0.1415931045969354, 300: 0.10411808794137242, 3000: 0.05367255163224517, 30000: 0.014760992671552299, 300000: 0.0012075283144570286}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1601/30001 [24:11<10:04:12,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.665931449094316, 30: 0.14516317926296066, 300: 0.10963850718301062, 3000: 0.06027482823235478, 30000: 0.017274359775140538, 300000: 0.001698157401623985, 30000000: 1.9519050593379137e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1701/30001 [26:17<9:22:44,  1.19s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6481297766019988, 30: 0.14831349206349206, 300: 0.11449147560258671, 3000: 0.06659685479129923, 30000: 0.020190329218106994, 300000: 0.002259700176366843, 30000000: 1.8371546149323927e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1801/30001 [28:20<9:04:49,  1.16s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6310383120488617, 30: 0.14993406440866186, 300: 0.11934342032204331, 3000: 0.07360494169905608, 30000: 0.023337729039422543, 300000: 0.002724181010549695, 30000000: 1.7351471404775126e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 1901/30001 [30:26<10:07:51,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6114, 30: 0.15405, 300: 0.12505, 3000: 0.07975, 30000: 0.02655, 300000: 0.003183333333333333, 30000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2001/30001 [32:36<9:52:27,  1.27s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.5837666666666667, 30: 0.1577, 300: 0.13423333333333334, 3000: 0.08866666666666667, 30000: 0.0314, 300000: 0.004216666666666666, 30000000: 1.6666666666666667e-05}\n",
      "Agent checkpoint saved at iteration 2000 in 5.\n",
      "Model checkpoint saved at iteration 2000 in 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2101/30001 [34:50<11:02:42,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.5507666666666666, 30: 0.16621666666666668, 300: 0.14375, 3000: 0.09706666666666666, 30000: 0.03695, 300000: 0.005233333333333334, 30000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2201/30001 [36:55<10:02:59,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.5160833333333333, 30: 0.17525, 300: 0.15345, 3000: 0.10645, 30000: 0.042466666666666666, 300000: 0.006266666666666667, 30000000: 1.6666666666666667e-05, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2301/30001 [39:07<13:06:28,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.48368333333333335, 30: 0.18251666666666666, 300: 0.16221666666666668, 3000: 0.1166, 30000: 0.0476, 300000: 0.00735, 30000000: 1.6666666666666667e-05, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2401/30001 [42:02<10:29:45,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.4550166666666667, 300: 0.17025, 30: 0.18433333333333332, 3000: 0.12663333333333332, 30000: 0.054966666666666664, 300000: 0.008766666666666667, 30000000: 1.6666666666666667e-05, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2501/30001 [44:26<10:51:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.4326, 30: 0.18428333333333333, 3000: 0.13588333333333333, 300: 0.17525, 30000: 0.06175, 300000: 0.0102, 30000000: 1.6666666666666667e-05, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 2601/30001 [46:44<10:36:43,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.4122, 300: 0.18011666666666667, 30: 0.18358333333333332, 3000: 0.1442, 30000: 0.06831666666666666, 300000: 0.01155, 30000000: 1.6666666666666667e-05, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2701/30001 [49:37<15:07:36,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.3957833333333333, 3000: 0.1526, 300: 0.18256666666666665, 30: 0.1812, 30000: 0.07471666666666667, 300000: 0.0131, 30000000: 1.6666666666666667e-05, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2801/30001 [53:07<16:29:33,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.3826333333333333, 30: 0.17968333333333333, 300: 0.1856, 3000: 0.15846666666666667, 30000: 0.07956666666666666, 300000: 0.014016666666666667, 30000000: 1.6666666666666667e-05, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 2901/30001 [56:04<11:07:22,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.17893333333333333, 1: 0.3757, 300: 0.18498333333333333, 3000: 0.16248333333333334, 30000: 0.08311666666666667, 300000: 0.01475, 30000000: 1.6666666666666667e-05, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3001/30001 [58:49<12:18:37,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.37051666666666666, 30: 0.17681666666666668, 3000: 0.1657, 300: 0.18451666666666666, 30000: 0.08671666666666666, 300000: 0.0157, 30000000: 1.6666666666666667e-05, 3000000: 1.6666666666666667e-05}\n",
      "Agent checkpoint saved at iteration 3000 in 5.\n",
      "Model checkpoint saved at iteration 3000 in 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3101/30001 [1:01:32<13:11:14,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.36695, 300: 0.18345, 30: 0.17365, 30000: 0.09068333333333334, 3000: 0.16888333333333333, 300000: 0.01635, 30000000: 1.6666666666666667e-05, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3201/30001 [1:04:22<12:23:19,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.3686833333333333, 3000: 0.16875, 30000: 0.09276666666666666, 300: 0.18028333333333332, 30: 0.17271666666666666, 300000: 0.016766666666666666, 30000000: 1.6666666666666667e-05, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3301/30001 [1:07:13<12:28:43,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.17788333333333334, 1: 0.37078333333333335, 30: 0.17208333333333334, 3000: 0.16786666666666666, 30000: 0.09403333333333333, 300000: 0.017316666666666668, 30000000: 1.6666666666666667e-05, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 3401/30001 [1:10:06<13:52:25,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.3747, 3000: 0.16653333333333334, 300: 0.17626666666666665, 30: 0.17043333333333333, 30000: 0.09448333333333334, 300000: 0.01755, 30000000: 1.6666666666666667e-05, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3501/30001 [1:12:59<13:18:40,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.37926666666666664, 300: 0.17421666666666666, 3000: 0.16426666666666667, 30000: 0.09525, 300000: 0.017683333333333332, 30: 0.1693, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3601/30001 [1:16:11<16:35:54,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.3847833333333333, 3000: 0.16118333333333335, 300000: 0.017466666666666665, 300: 0.17223333333333332, 30: 0.16926666666666668, 30000: 0.09505, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3701/30001 [1:19:23<12:10:46,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.15731666666666666, 1: 0.3923333333333333, 300: 0.1698, 30000: 0.09438333333333333, 30: 0.16875, 300000: 0.0174, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 3801/30001 [1:22:18<14:08:43,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.16786666666666666, 3000: 0.15558333333333332, 30: 0.16958333333333334, 1: 0.39591666666666664, 30000: 0.09385, 300000: 0.01718333333333333, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 3901/30001 [1:25:20<13:30:26,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.16693333333333332, 3000: 0.15325, 30: 0.1696, 1: 0.4019666666666667, 30000: 0.0917, 300000: 0.016533333333333334, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4001/30001 [1:28:06<11:52:44,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.16543333333333332, 30000: 0.08986666666666666, 30: 0.17058333333333334, 1: 0.40618333333333334, 3000: 0.15181666666666666, 300000: 0.0161, 3000000: 1.6666666666666667e-05}\n",
      "Agent checkpoint saved at iteration 4000 in 5.\n",
      "Model checkpoint saved at iteration 4000 in 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 4101/30001 [1:30:48<10:35:01,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.16498333333333334, 1: 0.41265, 300000: 0.015616666666666666, 3000: 0.14881666666666668, 30000: 0.08743333333333334, 30: 0.1705}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4201/30001 [1:33:31<12:52:14,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.14495, 30: 0.17316666666666666, 300: 0.16498333333333334, 30000: 0.08513333333333334, 1: 0.41691666666666666, 300000: 0.01485}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4301/30001 [1:36:57<13:14:41,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.17623333333333333, 300: 0.16398333333333334, 30000: 0.0819, 300000: 0.013916666666666667, 3000: 0.14151666666666668, 1: 0.42245}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 4401/30001 [1:40:06<13:59:21,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.13781666666666667, 30000: 0.07743333333333334, 1: 0.42993333333333333, 300: 0.1634, 30: 0.1785, 300000: 0.012916666666666667}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 4501/30001 [1:42:58<11:47:26,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.1344, 30000: 0.07405, 30: 0.18136666666666668, 1: 0.4366, 300: 0.16183333333333333, 300000: 0.01175}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 4601/30001 [1:46:05<11:33:53,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.1314, 30000: 0.07005, 30: 0.18466666666666667, 300: 0.16156666666666666, 1: 0.4417333333333333, 300000: 0.010583333333333333}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4701/30001 [1:49:04<12:51:33,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.44471666666666665, 3000: 0.12961666666666666, 300000: 0.0099, 30000: 0.06785, 300: 0.1616, 30: 0.18631666666666666}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4801/30001 [1:52:54<13:13:17,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.18715, 1: 0.44698333333333334, 30000: 0.06676666666666667, 300: 0.16251666666666667, 3000: 0.12743333333333334, 300000: 0.00915}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 4901/30001 [1:55:50<11:19:14,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.18908333333333333, 1: 0.4503333333333333, 3000: 0.12568333333333334, 300: 0.16136666666666666, 30000: 0.06496666666666667, 300000: 0.008566666666666667}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5001/30001 [1:58:59<12:18:13,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.16073333333333334, 1: 0.45308333333333334, 30000: 0.06311666666666667, 30: 0.19216666666666668, 3000: 0.12288333333333333, 300000: 0.008016666666666667}\n",
      "Agent checkpoint saved at iteration 5000 in 5.\n",
      "Model checkpoint saved at iteration 5000 in 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5101/30001 [2:01:57<11:35:16,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30000: 0.062016666666666664, 30: 0.19311666666666666, 3000: 0.12211666666666667, 300: 0.16031666666666666, 1: 0.45455, 300000: 0.007883333333333332}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5201/30001 [2:04:40<11:27:24,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30000: 0.06256666666666667, 1: 0.4527333333333333, 300: 0.16, 3000: 0.12336666666666667, 30: 0.1937, 300000: 0.007633333333333333}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5301/30001 [2:07:26<11:34:45,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.45148333333333335, 30: 0.19376666666666667, 300: 0.15978333333333333, 3000: 0.12478333333333333, 30000: 0.062483333333333335, 300000: 0.0077}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5401/30001 [2:10:16<11:48:50,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.45016666666666666, 300000: 0.007366666666666666, 30: 0.1949, 300: 0.15991666666666668, 3000: 0.12543333333333334, 30000: 0.06221666666666667}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5501/30001 [2:13:17<15:55:06,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.12568333333333334, 30: 0.19645, 1: 0.4488666666666667, 300: 0.16008333333333333, 30000: 0.06166666666666667, 300000: 0.00725}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 5601/30001 [2:16:30<13:21:34,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.12551666666666667, 1: 0.44798333333333334, 30: 0.19818333333333332, 300: 0.16018333333333334, 30000: 0.06105, 300000: 0.007083333333333333}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5701/30001 [2:19:34<14:06:25,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.15993333333333334, 30000: 0.05995, 1: 0.44948333333333335, 3000: 0.12506666666666666, 30: 0.19856666666666667, 300000: 0.007}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5801/30001 [2:23:05<14:28:32,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.45065, 30: 0.1997, 3000: 0.12411666666666667, 300: 0.15991666666666668, 30000: 0.05878333333333333, 300000: 0.006833333333333334}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 5901/30001 [2:26:11<11:42:05,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.1595, 3000: 0.12248333333333333, 30000: 0.0574, 1: 0.4540666666666667, 30: 0.20025, 300000: 0.0063}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6001/30001 [2:29:21<13:48:20,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.20091666666666666, 1: 0.4579166666666667, 300: 0.15828333333333333, 30000: 0.05606666666666667, 3000: 0.12085, 300000: 0.005966666666666667}\n",
      "Agent checkpoint saved at iteration 6000 in 5.\n",
      "Model checkpoint saved at iteration 6000 in 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6101/30001 [2:32:41<16:27:08,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.20113333333333333, 30000: 0.053733333333333334, 1: 0.46385, 3000: 0.11888333333333333, 300: 0.15693333333333334, 300000: 0.0054666666666666665}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6201/30001 [2:36:08<13:32:52,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.11655, 300: 0.15515, 1: 0.46971666666666667, 30: 0.20111666666666667, 30000: 0.05223333333333333, 300000: 0.005233333333333334}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6301/30001 [2:39:13<11:37:17,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.2014, 30000: 0.050833333333333335, 1: 0.4755333333333333, 3000: 0.1142, 300: 0.15296666666666667, 300000: 0.005066666666666666}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 6401/30001 [2:42:32<12:06:10,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.1507, 1: 0.4825833333333333, 3000: 0.11185, 30: 0.20066666666666666, 30000: 0.04936666666666667, 300000: 0.004833333333333334}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6501/30001 [2:45:14<11:21:10,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.14956666666666665, 1: 0.4867166666666667, 30: 0.19983333333333334, 30000: 0.04865, 3000: 0.11051666666666667, 300000: 0.004716666666666667}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6601/30001 [2:48:03<11:25:55,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.49291666666666667, 3000: 0.10798333333333333, 300: 0.14735, 30: 0.19971666666666665, 30000: 0.04738333333333333, 300000: 0.00465}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6701/30001 [2:51:41<13:47:14,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.49723333333333336, 300: 0.14555, 30000: 0.04565, 30: 0.19921666666666665, 3000: 0.10751666666666666, 300000: 0.004833333333333334}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 6801/30001 [2:54:51<12:09:49,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.1068, 300: 0.14566666666666667, 30000: 0.0442, 1: 0.49996666666666667, 30: 0.19875, 300000: 0.0046166666666666665}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 6901/30001 [2:57:29<9:07:09,  1.42s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30000: 0.043366666666666664, 1: 0.5013666666666666, 300: 0.14588333333333334, 30: 0.19793333333333332, 3000: 0.10678333333333333, 300000: 0.004666666666666667}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7001/30001 [3:00:10<10:28:59,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.507, 30: 0.19866666666666666, 30000: 0.0408, 3000: 0.10421666666666667, 300: 0.14505, 300000: 0.004266666666666667}\n",
      "Agent checkpoint saved at iteration 7000 in 5.\n",
      "Model checkpoint saved at iteration 7000 in 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 7101/30001 [3:03:01<11:17:21,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30000: 0.037766666666666664, 3000: 0.10003333333333334, 300: 0.14295, 30: 0.19973333333333335, 1: 0.5157, 300000: 0.0038166666666666666}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7201/30001 [3:05:47<11:31:08,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30000: 0.0348, 3000: 0.09593333333333333, 300: 0.14071666666666666, 1: 0.5246666666666666, 30: 0.20041666666666666, 300000: 0.0034666666666666665}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7301/30001 [3:08:37<11:12:15,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.09285, 30: 0.20055, 300: 0.139, 1: 0.53205, 30000: 0.03233333333333333, 300000: 0.0032166666666666667}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 7401/30001 [3:11:30<11:32:44,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.13663333333333333, 30000: 0.030366666666666667, 3000: 0.08978333333333334, 1: 0.53935, 30: 0.2009, 300000: 0.00295, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 7501/30001 [3:14:42<11:59:17,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.2002, 1: 0.5464, 300000: 0.0028166666666666665, 3000: 0.08771666666666667, 300: 0.13423333333333334, 30000: 0.028616666666666665, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 7601/30001 [3:18:00<11:08:19,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.13183333333333333, 1: 0.5524333333333333, 3000: 0.08536666666666666, 30: 0.20053333333333334, 30000: 0.027216666666666667, 300000: 0.0026, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 7701/30001 [3:21:40<12:11:27,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30000: 0.02585, 3000: 0.08285, 1: 0.5590833333333334, 30: 0.20033333333333334, 300: 0.12946666666666667, 300000: 0.0024, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 7801/30001 [3:25:01<12:28:33,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.5659166666666666, 300: 0.12693333333333334, 3000: 0.08066666666666666, 30: 0.1996, 30000: 0.0246, 300000: 0.002266666666666667, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 7901/30001 [3:28:23<11:52:58,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.12528333333333333, 3000: 0.079, 30: 0.19896666666666665, 1: 0.5711666666666667, 30000: 0.023366666666666668, 300000: 0.0022, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8000/30001 [3:31:41<16:28:43,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.19896666666666665, 30000: 0.02295, 3000: 0.078, 1: 0.5736333333333333, 300: 0.12425, 300000: 0.002183333333333333, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8001/30001 [3:31:44<16:52:28,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent checkpoint saved at iteration 8000 in 5.\n",
      "Model checkpoint saved at iteration 8000 in 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8101/30001 [3:35:10<11:14:34,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.5757, 300: 0.12433333333333334, 300000: 0.002183333333333333, 3000: 0.07786666666666667, 30: 0.19766666666666666, 30000: 0.022233333333333334, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8201/30001 [3:38:20<11:47:53,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30000: 0.021916666666666668, 30: 0.19603333333333334, 3000: 0.07876666666666667, 1: 0.5759666666666666, 300: 0.1251, 300000: 0.0022, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 8301/30001 [3:41:33<10:22:51,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30000: 0.021466666666666665, 300: 0.1257, 3000: 0.07923333333333334, 30: 0.19471666666666668, 1: 0.57665, 300000: 0.0022166666666666667, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 8401/30001 [3:44:23<10:50:57,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.12516666666666668, 1: 0.58095, 30: 0.19385, 30000: 0.020116666666666668, 3000: 0.07785, 300000: 0.00205, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 8501/30001 [3:47:49<16:00:08,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.07636666666666667, 300: 0.12283333333333334, 1: 0.5858333333333333, 30: 0.19413333333333332, 30000: 0.018916666666666665, 300000: 0.0019, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 8601/30001 [3:51:08<11:08:08,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.59495, 3000: 0.07308333333333333, 30: 0.19371666666666668, 300: 0.1191, 30000: 0.017516666666666666, 300000: 0.0016166666666666666, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 8701/30001 [3:54:42<11:55:57,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.07028333333333334, 1: 0.6049833333333333, 30: 0.19225, 300: 0.1145, 30000: 0.0164, 300000: 0.0015666666666666667, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 8801/30001 [3:58:02<13:09:08,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6130666666666666, 30: 0.1922, 3000: 0.06755, 300: 0.1105, 30000: 0.015333333333333332, 300000: 0.0013333333333333333, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 8901/30001 [4:01:39<14:43:29,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6199666666666667, 30: 0.18951666666666667, 300: 0.10756666666666667, 3000: 0.06633333333333333, 30000: 0.0153, 300000: 0.0013, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9001/30001 [4:05:04<11:02:14,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.19135, 3000: 0.06626666666666667, 1: 0.6186666666666667, 300: 0.10686666666666667, 30000: 0.0155, 300000: 0.0013333333333333333, 3000000: 1.6666666666666667e-05}\n",
      "Agent checkpoint saved at iteration 9000 in 5.\n",
      "Model checkpoint saved at iteration 9000 in 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9101/30001 [4:08:25<12:19:03,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.1071, 30: 0.19246666666666667, 1: 0.6157166666666667, 3000: 0.06741666666666667, 30000: 0.015883333333333333, 300000: 0.0014, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 9201/30001 [4:12:02<14:19:44,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.61205, 300: 0.10705, 3000: 0.06851666666666667, 30: 0.19385, 30000: 0.01695, 300000: 0.0015833333333333333}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 9301/30001 [4:16:00<12:20:38,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.1954, 1: 0.6096833333333334, 300: 0.10695, 3000: 0.0689, 30000: 0.017383333333333334, 300000: 0.0016833333333333333}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 9401/30001 [4:19:15<10:59:46,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6083166666666666, 30: 0.19721666666666668, 30000: 0.017666666666666667, 300: 0.10663333333333333, 3000: 0.0685, 300000: 0.0016666666666666668}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 9501/30001 [4:22:29<10:52:51,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6052, 300: 0.1066, 30: 0.19908333333333333, 30000: 0.018483333333333334, 3000: 0.06885, 300000: 0.0017833333333333334}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 9601/30001 [4:26:11<11:20:25,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6020166666666666, 3000: 0.06923333333333333, 300: 0.10605, 30: 0.20155, 30000: 0.019233333333333335, 300000: 0.0019166666666666666}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 9701/30001 [4:29:33<13:54:26,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.5969, 30: 0.20481666666666667, 300: 0.10621666666666667, 3000: 0.07, 300000: 0.0020666666666666667, 30000: 0.019983333333333332, 30000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 9801/30001 [4:33:00<10:53:54,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.5926166666666667, 300: 0.10578333333333333, 30: 0.20905, 3000: 0.07008333333333333, 30000: 0.0203, 300000: 0.00215, 30000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 9901/30001 [4:36:17<11:03:59,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.5897833333333333, 3000: 0.07068333333333333, 300: 0.10565, 30: 0.21081666666666668, 30000: 0.0208, 300000: 0.00225, 30000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10001/30001 [4:39:37<11:12:31,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.06941666666666667, 1: 0.5882833333333334, 30: 0.21468333333333334, 300: 0.10418333333333334, 30000: 0.0211, 300000: 0.0023166666666666665, 30000000: 1.6666666666666667e-05}\n",
      "Agent checkpoint saved at iteration 10000 in 5.\n",
      "Model checkpoint saved at iteration 10000 in 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 10101/30001 [4:43:14<11:50:56,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.21938333333333335, 1: 0.5863, 300: 0.1024, 3000: 0.06801666666666667, 30000: 0.021516666666666667, 300000: 0.0023666666666666667, 30000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 10201/30001 [4:45:19<7:25:36,  1.35s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.5806333333333333, 300000: 0.0023166666666666665, 3000: 0.0662, 300: 0.10425, 30: 0.22536666666666666, 30000: 0.02121666666666667, 30000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 10301/30001 [4:47:45<8:38:16,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.23313333333333333, 3000: 0.06443333333333333, 300: 0.10448333333333333, 1: 0.5751333333333334, 30000: 0.0205, 300000: 0.0023, 30000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 10401/30001 [4:50:29<11:22:03,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.5678166666666666, 3000: 0.06258333333333334, 30: 0.24085, 300: 0.10638333333333333, 30000: 0.020116666666666668, 300000: 0.0022333333333333333, 30000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 10501/30001 [4:53:18<8:57:12,  1.65s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.24966666666666668, 300: 0.11003333333333333, 1: 0.5564333333333333, 3000: 0.06193333333333333, 30000: 0.019683333333333334, 300000: 0.0022333333333333333, 30000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 10601/30001 [4:56:17<9:45:49,  1.81s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.1117, 30: 0.2595, 1: 0.5472666666666667, 30000: 0.01925, 3000: 0.0601, 300000: 0.0021666666666666666, 30000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 10701/30001 [4:59:16<9:29:37,  1.77s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.5364, 30: 0.26995, 3000: 0.0593, 300: 0.1136, 30000: 0.0186, 300000: 0.0021333333333333334, 30000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 10801/30001 [5:02:30<10:26:47,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.11566666666666667, 3000: 0.05756666666666667, 1: 0.5259333333333334, 30: 0.28076666666666666, 30000: 0.017966666666666666, 300000: 0.0020833333333333333, 30000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 10901/30001 [5:05:33<9:49:47,  1.85s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.288, 1: 0.5218, 30000: 0.01718333333333333, 300: 0.11608333333333333, 3000: 0.055016666666666665, 300000: 0.0019, 30000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11001/30001 [5:08:39<9:49:44,  1.86s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.51705, 30: 0.2957, 30000: 0.016433333333333335, 3000: 0.05293333333333333, 300000: 0.0018333333333333333, 300: 0.11603333333333334, 30000000: 1.6666666666666667e-05}\n",
      "Agent checkpoint saved at iteration 11000 in 5.\n",
      "Model checkpoint saved at iteration 11000 in 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11101/30001 [5:11:49<10:11:00,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.5133833333333333, 30: 0.3007166666666667, 3000: 0.051866666666666665, 300: 0.11663333333333334, 30000: 0.015666666666666666, 300000: 0.0017166666666666667, 30000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11201/30001 [5:15:03<10:27:33,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.50845, 300: 0.11785, 3000: 0.05176666666666667, 30: 0.3046333333333333, 30000: 0.015533333333333333, 300000: 0.00175, 30000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 11301/30001 [5:18:20<10:16:27,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.05163333333333334, 30000: 0.0151, 1: 0.5054166666666666, 30: 0.30791666666666667, 300: 0.11825, 300000: 0.0016666666666666668, 30000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 11401/30001 [5:21:56<10:12:10,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.5011666666666666, 30: 0.31151666666666666, 3000: 0.0511, 30000: 0.014433333333333333, 300: 0.12008333333333333, 300000: 0.0016833333333333333, 30000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 11501/30001 [5:25:48<13:57:51,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.050666666666666665, 300: 0.12111666666666666, 1: 0.49825, 30: 0.31406666666666666, 30000: 0.014266666666666667, 300000: 0.0016166666666666666, 30000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 11601/30001 [5:29:30<13:56:39,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.12175, 1: 0.49538333333333334, 3000: 0.050916666666666666, 30: 0.31648333333333334, 30000: 0.013933333333333334, 300000: 0.0015333333333333334}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 11701/30001 [5:33:10<9:27:38,  1.86s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.49265, 30: 0.31875, 3000: 0.051083333333333335, 300: 0.12218333333333334, 30000: 0.0139, 300000: 0.0014333333333333333}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 11801/30001 [5:35:55<8:34:59,  1.70s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.3189666666666667, 30000: 0.0132, 3000: 0.0506, 1: 0.4921, 300: 0.12386666666666667, 300000: 0.00125, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 11901/30001 [5:38:30<8:17:12,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.32348333333333334, 300: 0.12301666666666666, 30000: 0.012116666666666666, 3000: 0.04833333333333333, 1: 0.49188333333333334, 300000: 0.00115, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12001/30001 [5:41:15<8:27:49,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.3299666666666667, 300: 0.12208333333333334, 1: 0.49011666666666664, 3000: 0.04608333333333333, 30000: 0.0108, 300000: 0.0009333333333333333, 3000000: 1.6666666666666667e-05}\n",
      "Agent checkpoint saved at iteration 12000 in 5.\n",
      "Model checkpoint saved at iteration 12000 in 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12101/30001 [5:44:23<8:49:57,  1.78s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.33341666666666664, 1: 0.49283333333333335, 3000: 0.04421666666666667, 300: 0.11833333333333333, 30000: 0.010266666666666667, 300000: 0.0009166666666666666, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 12201/30001 [5:47:16<8:37:41,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.49018333333333336, 30: 0.3376, 300: 0.11806666666666667, 30000: 0.010116666666666666, 3000: 0.043083333333333335, 300000: 0.0009166666666666666, 3000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 12301/30001 [5:50:18<8:23:34,  1.71s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.3401166666666667, 1: 0.4882, 300: 0.1181, 3000: 0.0425, 30000: 0.010133333333333333, 300000: 0.0009166666666666666, 3000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 12401/30001 [5:53:16<8:58:15,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.11846666666666666, 30: 0.3439, 1: 0.48411666666666664, 3000: 0.042366666666666664, 30000: 0.010183333333333334, 300000: 0.0009333333333333333, 3000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 12501/30001 [5:56:26<8:37:00,  1.77s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.4782166666666667, 30: 0.348, 300: 0.12015, 3000: 0.0424, 300000: 0.0009166666666666666, 30000: 0.010283333333333334, 3000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 12601/30001 [5:59:30<9:16:07,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.34823333333333334, 300: 0.12191666666666667, 1: 0.4756666666666667, 3000: 0.04275, 30000: 0.0105, 300000: 0.0009, 3000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 12701/30001 [6:02:35<8:53:06,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.34915, 1: 0.47126666666666667, 300: 0.12393333333333334, 3000: 0.04385, 30000: 0.010833333333333334, 300000: 0.0009333333333333333, 3000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 12801/30001 [6:05:43<9:21:42,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.34825, 1: 0.4693333333333333, 300: 0.12523333333333334, 3000: 0.04488333333333333, 30000: 0.011266666666666666, 300000: 0.001, 3000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 12901/30001 [6:09:02<9:01:39,  1.90s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.4686, 30: 0.34745, 300: 0.12578333333333333, 3000: 0.04533333333333334, 30000: 0.011766666666666667, 300000: 0.0010166666666666666, 3000000: 3.3333333333333335e-05, 300000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13001/30001 [6:12:24<9:34:50,  2.03s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.4683, 30: 0.34735, 3000: 0.04525, 300: 0.12658333333333333, 300000: 0.0009333333333333333, 30000: 0.011533333333333333, 3000000: 3.3333333333333335e-05, 300000000000: 1.6666666666666667e-05}\n",
      "Agent checkpoint saved at iteration 13000 in 5.\n",
      "Model checkpoint saved at iteration 13000 in 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 13101/30001 [6:15:44<9:12:04,  1.96s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.04541666666666667, 30: 0.3473, 300: 0.12836666666666666, 1: 0.46636666666666665, 30000: 0.0116, 300000: 0.0009, 3000000: 3.3333333333333335e-05, 300000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 13201/30001 [6:19:02<9:32:19,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.12968333333333334, 1: 0.4629333333333333, 3000: 0.04545, 30: 0.34918333333333335, 300000: 0.0009, 30000: 0.0118, 3000000: 3.3333333333333335e-05, 300000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 13301/30001 [6:22:30<9:04:32,  1.96s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.46091666666666664, 300: 0.12965, 30: 0.34976666666666667, 3000: 0.046566666666666666, 30000: 0.012183333333333332, 300000: 0.0008666666666666666, 3000000: 3.3333333333333335e-05, 300000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 13401/30001 [6:25:51<9:02:57,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.35165, 1: 0.45681666666666665, 300: 0.13126666666666667, 30000: 0.012116666666666666, 3000: 0.04725, 300000: 0.00085, 3000000: 3.3333333333333335e-05, 300000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 13501/30001 [6:29:13<9:12:08,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.04745, 300: 0.13178333333333334, 1: 0.45531666666666665, 30: 0.35228333333333334, 30000: 0.012233333333333334, 300000: 0.0008833333333333333, 3000000: 3.3333333333333335e-05, 300000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 13601/30001 [6:32:38<9:21:09,  2.05s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.13311666666666666, 3000: 0.04703333333333334, 1: 0.45385, 30: 0.3531666666666667, 30000: 0.011883333333333333, 300000: 0.0009166666666666666, 3000000: 1.6666666666666667e-05, 300000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 13701/30001 [6:36:04<9:21:34,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.35683333333333334, 1: 0.4465, 300: 0.13373333333333334, 3000: 0.048966666666666665, 30000: 0.012916666666666667, 300000: 0.0010166666666666666, 3000000: 1.6666666666666667e-05, 300000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 13801/30001 [6:39:36<9:28:28,  2.11s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.13635, 1: 0.4416833333333333, 30: 0.35446666666666665, 3000: 0.05205, 30000: 0.014316666666666667, 3000000: 1.6666666666666667e-05, 300000: 0.0011, 300000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 13901/30001 [6:43:07<9:17:05,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.13766666666666666, 30: 0.3524, 1: 0.43875, 30000: 0.015366666666666667, 3000: 0.054533333333333336, 3000000: 1.6666666666666667e-05, 300000: 0.00125, 300000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14001/30001 [6:46:41<9:45:07,  2.19s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.4383166666666667, 30: 0.34773333333333334, 300: 0.13846666666666665, 3000: 0.05728333333333333, 30000: 0.016816666666666667, 300000: 0.0013666666666666666, 300000000000: 1.6666666666666667e-05}\n",
      "Agent checkpoint saved at iteration 14000 in 5.\n",
      "Model checkpoint saved at iteration 14000 in 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14101/30001 [6:50:17<9:37:36,  2.18s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.44051666666666667, 30: 0.34145, 30000: 0.017866666666666666, 300: 0.1385, 3000: 0.06018333333333333, 300000: 0.0014666666666666667, 300000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14201/30001 [6:53:51<9:40:54,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.4408166666666667, 30: 0.33726666666666666, 300: 0.1387, 3000: 0.063, 30000: 0.01863333333333333, 300000: 0.0015666666666666667, 300000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 14301/30001 [6:57:35<9:57:41,  2.28s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.33155, 1: 0.44275, 300: 0.13911666666666667, 3000: 0.06515, 30000: 0.019783333333333333, 300000: 0.0016333333333333334, 300000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 14401/30001 [7:01:18<9:50:32,  2.27s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.3262, 1: 0.4451, 300: 0.13878333333333334, 3000: 0.06731666666666666, 30000: 0.020816666666666667, 300000: 0.0017666666666666666, 300000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 14501/30001 [7:05:04<9:44:38,  2.26s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.06926666666666667, 1: 0.44716666666666666, 300: 0.13836666666666667, 30: 0.32158333333333333, 30000: 0.021716666666666665, 300000: 0.0018833333333333334, 300000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 14601/30001 [7:08:34<9:05:20,  2.12s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30000: 0.021983333333333334, 3000: 0.07076666666666667, 300: 0.13786666666666667, 1: 0.4507833333333333, 30: 0.31656666666666666, 300000: 0.0020166666666666666, 300000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 14701/30001 [7:12:12<9:34:02,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.4526, 30: 0.31465, 300: 0.1367, 30000: 0.022416666666666668, 3000: 0.07161666666666666, 300000: 0.002, 300000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 14801/30001 [7:15:58<10:03:40,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.4542, 30000: 0.022683333333333333, 300: 0.13645, 30: 0.31288333333333335, 3000: 0.0718, 300000: 0.0019833333333333335}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 14901/30001 [7:19:44<9:27:58,  2.26s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.13586666666666666, 30000: 0.022533333333333332, 1: 0.45575, 3000: 0.07223333333333333, 30: 0.3116, 300000: 0.0020166666666666666}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15001/30001 [7:23:31<9:33:58,  2.30s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.07251666666666666, 1: 0.45666666666666667, 300: 0.13478333333333334, 30: 0.31125, 30000: 0.022766666666666668, 300000: 0.0020166666666666666}\n",
      "Agent checkpoint saved at iteration 15000 in 5.\n",
      "Model checkpoint saved at iteration 15000 in 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15101/30001 [7:27:20<9:19:57,  2.25s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.4582, 3000: 0.07311666666666666, 30000: 0.022533333333333332, 300: 0.13436666666666666, 30: 0.3098, 300000: 0.0019833333333333335}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 15201/30001 [7:31:18<9:44:19,  2.37s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.4595666666666667, 30: 0.30933333333333335, 300: 0.13385, 3000: 0.07276666666666666, 30000: 0.02255, 300000: 0.0019333333333333333}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 15301/30001 [7:35:08<9:26:10,  2.31s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30000: 0.022733333333333335, 30: 0.30835, 1: 0.4606, 300: 0.13401666666666667, 3000: 0.07236666666666666, 300000: 0.0019166666666666666, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 15401/30001 [7:38:23<3:38:43,  1.11it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.07126666666666667, 30: 0.3058666666666667, 1: 0.46536666666666665, 300: 0.13298333333333334, 30000: 0.022566666666666665, 300000: 0.0019333333333333333, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 15501/30001 [7:40:00<4:32:32,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.30115, 1: 0.47568333333333335, 3000: 0.06841666666666667, 300000: 0.00185, 300: 0.13125, 30000: 0.021633333333333334, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 15601/30001 [7:42:08<5:53:49,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.4786, 30: 0.2984833333333333, 3000: 0.06768333333333333, 300: 0.13285, 30000: 0.020616666666666665, 300000: 0.00175, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 15701/30001 [7:44:41<6:28:22,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.13526666666666667, 30: 0.29338333333333333, 1: 0.47931666666666667, 3000: 0.06938333333333334, 300000: 0.0017833333333333334, 30000: 0.02085, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 15801/30001 [7:47:19<6:24:33,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.4778, 30: 0.2887, 300: 0.13683333333333333, 3000: 0.07276666666666666, 30000: 0.021983333333333334, 300000: 0.0019, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 15901/30001 [7:50:07<6:40:47,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.47518333333333335, 300: 0.13821666666666665, 3000: 0.07691666666666666, 30: 0.28451666666666664, 30000: 0.0231, 300000: 0.002033333333333333, 3000000: 1.6666666666666667e-05, 300000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16001/30001 [7:52:56<6:30:42,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.27913333333333334, 1: 0.47275, 3000: 0.08045, 300: 0.14011666666666667, 30000: 0.025166666666666667, 300000: 0.00235, 3000000: 1.6666666666666667e-05, 300000000: 1.6666666666666667e-05}\n",
      "Agent checkpoint saved at iteration 16000 in 5.\n",
      "Model checkpoint saved at iteration 16000 in 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 16101/30001 [7:55:50<6:57:54,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.27303333333333335, 1: 0.47191666666666665, 300: 0.14113333333333333, 3000: 0.0844, 30000: 0.0269, 300000: 0.0025833333333333333, 3000000: 1.6666666666666667e-05, 300000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 16201/30001 [7:59:08<6:51:43,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.1421, 1: 0.4699833333333333, 30: 0.26715, 3000: 0.0893, 30000: 0.028616666666666665, 300000: 0.0028, 3000000: 3.3333333333333335e-05, 300000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 16301/30001 [8:02:04<7:06:24,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.47003333333333336, 30: 0.26125, 300: 0.14251666666666668, 3000: 0.09258333333333334, 30000: 0.030483333333333335, 300000: 0.00305, 3000000: 5e-05, 300000000: 1.6666666666666667e-05, 30000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 16401/30001 [8:05:09<7:17:34,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30000: 0.03238333333333333, 1: 0.4702, 30: 0.25638333333333335, 3000: 0.09555, 300: 0.14221666666666666, 300000: 0.0031666666666666666, 3000000: 5e-05, 300000000: 1.6666666666666667e-05, 30000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 16501/30001 [8:08:20<7:08:37,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300000: 0.0034, 1: 0.47053333333333336, 30: 0.2515, 3000: 0.09856666666666666, 300: 0.14101666666666668, 30000: 0.034883333333333336, 3000000: 5e-05, 300000000: 1.6666666666666667e-05, 30000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 16601/30001 [8:12:28<10:03:45,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.4701166666666667, 30: 0.24846666666666667, 3000: 0.10036666666666667, 300: 0.14088333333333333, 30000: 0.03651666666666667, 300000: 0.00355, 3000000: 5e-05, 300000000: 1.6666666666666667e-05, 30000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 16701/30001 [8:16:51<9:41:30,  2.62s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30000: 0.03766666666666667, 3000: 0.10186666666666666, 30: 0.24693333333333334, 1: 0.46971666666666667, 300: 0.13995, 300000: 0.003766666666666667, 3000000: 5e-05, 300000000: 1.6666666666666667e-05, 30000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 16801/30001 [8:21:16<10:03:09,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.4698, 30: 0.24488333333333334, 3000: 0.10256666666666667, 30000: 0.03841666666666667, 300: 0.1404, 300000: 0.003833333333333333, 3000000: 5e-05, 300000000: 1.6666666666666667e-05, 30000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 16901/30001 [8:25:44<9:36:04,  2.64s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.13998333333333332, 30: 0.24275, 1: 0.47035, 3000: 0.1034, 30000: 0.03945, 300000: 0.003966666666666667, 3000000: 5e-05, 300000000: 1.6666666666666667e-05, 30000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17001/30001 [8:30:18<10:30:53,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.10416666666666667, 30000: 0.04031666666666667, 300: 0.13958333333333334, 1: 0.47, 30: 0.24163333333333334, 300000: 0.0042, 3000000: 5e-05, 300000000: 1.6666666666666667e-05, 30000000: 3.3333333333333335e-05}\n",
      "Agent checkpoint saved at iteration 17000 in 5.\n",
      "Model checkpoint saved at iteration 17000 in 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17101/30001 [8:34:55<9:47:55,  2.73s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.10338333333333333, 30: 0.23921666666666666, 1: 0.4755333333333333, 300: 0.13755, 30000: 0.03995, 300000: 0.004266666666666667, 3000000: 5e-05, 300000000: 1.6666666666666667e-05, 30000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17201/30001 [8:39:40<10:17:08,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.1026, 30: 0.23701666666666665, 1: 0.4814833333333333, 300: 0.1351, 30000: 0.0395, 300000: 0.004216666666666666, 300000000: 1.6666666666666667e-05, 3000000: 3.3333333333333335e-05, 30000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 17301/30001 [8:44:22<10:08:29,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.47801666666666665, 30: 0.23895, 300: 0.13515, 3000: 0.1037, 30000: 0.0398, 300000: 0.0043, 300000000: 1.6666666666666667e-05, 3000000: 3.3333333333333335e-05, 30000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 17401/30001 [8:49:06<9:58:47,  2.85s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.13331666666666667, 30: 0.23966666666666667, 1: 0.47805, 3000: 0.1042, 30000: 0.04035, 300000: 0.004333333333333333, 300000000: 1.6666666666666667e-05, 3000000: 3.3333333333333335e-05, 30000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 17501/30001 [8:53:51<10:11:56,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30000: 0.04036666666666667, 1: 0.4829333333333333, 300: 0.12946666666666667, 30: 0.23978333333333332, 3000: 0.10303333333333334, 300000: 0.004333333333333333, 300000000: 1.6666666666666667e-05, 3000000: 3.3333333333333335e-05, 30000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 17601/30001 [8:58:22<9:31:28,  2.77s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.49068333333333336, 3000: 0.09938333333333334, 30000: 0.0392, 30: 0.24135, 300: 0.12508333333333332, 300000: 0.004216666666666666, 300000000: 1.6666666666666667e-05, 3000000: 3.3333333333333335e-05, 30000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 17701/30001 [9:03:04<9:46:42,  2.86s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.498, 3000: 0.0941, 30: 0.24455, 300: 0.12186666666666666, 30000: 0.0374, 300000: 0.004, 300000000: 1.6666666666666667e-05, 3000000: 3.3333333333333335e-05, 30000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 17801/30001 [9:07:48<9:31:19,  2.81s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300000: 0.0038166666666666666, 3000: 0.08836666666666666, 300: 0.11768333333333333, 30: 0.24691666666666667, 1: 0.5081333333333333, 30000: 0.03501666666666667, 3000000: 3.3333333333333335e-05, 30000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 17901/30001 [9:12:34<9:32:01,  2.84s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.25003333333333333, 300: 0.11381666666666666, 1: 0.5167, 30000: 0.032683333333333335, 300000: 0.00345, 3000: 0.08323333333333334, 3000000: 5e-05, 30000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18001/30001 [9:17:23<10:01:55,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.0777, 30: 0.25183333333333335, 30000: 0.030633333333333332, 300: 0.11055, 1: 0.5259, 300000: 0.0033, 3000000: 5e-05, 30000000: 3.3333333333333335e-05}\n",
      "Agent checkpoint saved at iteration 18000 in 5.\n",
      "Model checkpoint saved at iteration 18000 in 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18101/30001 [9:22:31<10:03:49,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.10725, 3000: 0.07288333333333333, 1: 0.53465, 30: 0.25416666666666665, 30000: 0.02805, 300000: 0.0029333333333333334, 3000000: 3.3333333333333335e-05, 30000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 18201/30001 [9:27:46<10:23:46,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.06836666666666667, 300: 0.10468333333333334, 1: 0.5427, 30: 0.2559666666666667, 30000: 0.02555, 300000: 0.0027, 30000000: 1.6666666666666667e-05, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 18301/30001 [9:32:58<10:29:24,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.06348333333333334, 300: 0.10348333333333333, 30000: 0.022616666666666667, 1: 0.5499833333333334, 30: 0.2579666666666667, 300000: 0.00245, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 18401/30001 [9:37:52<9:41:38,  3.01s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30000: 0.02036666666666667, 3000: 0.06041666666666667, 300: 0.10326666666666667, 1: 0.5540166666666667, 30: 0.25975, 300000: 0.0021666666666666666, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 18501/30001 [9:43:07<9:41:21,  3.03s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30000: 0.018383333333333335, 300: 0.10113333333333334, 30: 0.25998333333333334, 1: 0.5611833333333334, 3000: 0.057433333333333336, 300000: 0.0018666666666666666, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 18601/30001 [9:47:15<7:16:35,  2.30s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.0996, 1: 0.57005, 30: 0.25785, 3000: 0.054433333333333334, 30000: 0.01633333333333333, 300000: 0.0017166666666666667, 3000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23101/30001 [12:50:27<4:58:16,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.030733333333333335, 1: 0.6521333333333333, 300: 0.07555, 30: 0.23235, 30000: 0.007783333333333333, 300000: 0.0006666666666666666, 30000000: 0.0001, 3000000: 0.00023333333333333333, 300000000: 0.0001, 30000000000: 8.333333333333333e-05, 300000000000000: 1.6666666666666667e-05, 3000000000: 6.666666666666667e-05, 3000000000000: 0.00011666666666666667, 30000000000000000: 3.3333333333333335e-05, 300000000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23201/30001 [12:54:50<5:08:26,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6552666666666667, 30: 0.23161666666666667, 30000: 0.00765, 300: 0.07436666666666666, 3000: 0.02965, 300000: 0.0006666666666666666, 300000000: 0.00011666666666666667, 30000000000: 8.333333333333333e-05, 3000000: 0.00021666666666666666, 300000000000000: 1.6666666666666667e-05, 3000000000: 6.666666666666667e-05, 3000000000000: 0.00011666666666666667, 30000000000000000: 5e-05, 30000000: 8.333333333333333e-05, 300000000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 23301/30001 [12:59:13<4:35:36,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.23118333333333332, 1: 0.6566333333333333, 300: 0.07385, 3000: 0.0294, 3000000: 0.00021666666666666666, 30000: 0.007416666666666667, 300000000: 0.00011666666666666667, 300000: 0.0006833333333333333, 300000000000000: 1.6666666666666667e-05, 3000000000: 6.666666666666667e-05, 30000000000: 6.666666666666667e-05, 3000000000000: 0.00013333333333333334, 30000000000000000: 6.666666666666667e-05, 30000000: 0.0001, 300000000000: 5e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 23401/30001 [13:03:40<4:48:34,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6577333333333333, 30: 0.23168333333333332, 300: 0.0732, 3000: 0.0286, 30000: 0.007166666666666667, 300000: 0.0007166666666666667, 3000000: 0.00023333333333333333, 300000000000000: 1.6666666666666667e-05, 3000000000: 0.0001, 30000000000: 8.333333333333333e-05, 3000000000000: 0.00013333333333333334, 30000000000000000: 6.666666666666667e-05, 30000000: 0.0001, 300000000: 0.00011666666666666667, 300000000000: 5e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 23501/30001 [13:08:05<4:51:40,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6595166666666666, 300: 0.07303333333333334, 30: 0.23053333333333334, 3000: 0.02811666666666667, 300000000000000: 1.6666666666666667e-05, 30000: 0.0071333333333333335, 300000: 0.0007333333333333333, 3000000000: 0.00011666666666666667, 3000000: 0.00021666666666666666, 30000000000: 0.0001, 3000000000000: 0.00013333333333333334, 30000000000000000: 6.666666666666667e-05, 30000000: 0.00011666666666666667, 300000000: 0.00011666666666666667, 300000000000: 5e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 23601/30001 [13:12:33<4:37:47,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.07278333333333334, 1: 0.6602, 30: 0.23058333333333333, 3000: 0.027766666666666665, 30000: 0.007016666666666667, 300000: 0.0007, 3000000000: 0.00011666666666666667, 3000000: 0.00023333333333333333, 30000000000: 0.00011666666666666667, 3000000000000: 0.00013333333333333334, 30000000000000000: 6.666666666666667e-05, 30000000: 0.00011666666666666667, 300000000: 0.00011666666666666667, 300000000000: 5e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 23701/30001 [13:16:50<4:38:16,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.23165, 300: 0.0725, 1: 0.6596, 3000: 0.027516666666666665, 300000: 0.0007166666666666667, 30000: 0.007, 3000000000: 0.00011666666666666667, 3000000: 0.0002666666666666667, 30000000000: 0.00013333333333333334, 3000000000000: 0.00013333333333333334, 30000000000000000: 6.666666666666667e-05, 30000000: 0.00011666666666666667, 300000000: 0.00013333333333333334, 300000000000: 5e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 23801/30001 [13:21:15<4:33:44,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.027033333333333333, 1: 0.6618666666666667, 30: 0.23066666666666666, 300: 0.07181666666666667, 30000: 0.006933333333333333, 3000000000000: 0.00011666666666666667, 3000000000: 0.0001, 30000000000000000: 6.666666666666667e-05, 300000: 0.0006833333333333333, 30000000: 0.00013333333333333334, 300000000: 0.00013333333333333334, 30000000000: 0.00011666666666666667, 3000000: 0.00025, 300000000000: 6.666666666666667e-05, 3000000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 23901/30001 [13:25:39<4:29:39,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6625333333333333, 300: 0.07188333333333333, 30: 0.2304, 3000: 0.02665, 30000: 0.006783333333333333, 300000: 0.0007333333333333333, 30000000: 0.00015, 300000000: 0.00016666666666666666, 3000000000000: 8.333333333333333e-05, 30000000000: 0.00011666666666666667, 3000000: 0.00028333333333333335, 30000000000000000: 5e-05, 3000000000: 6.666666666666667e-05, 300000000000: 8.333333333333333e-05, 3000000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24001/30001 [13:29:59<4:18:13,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.23145, 1: 0.6622833333333333, 3000: 0.026516666666666668, 30000: 0.006883333333333333, 300: 0.0711, 30000000: 0.00015, 300000000: 0.00018333333333333334, 300000: 0.0006833333333333333, 3000000000000: 8.333333333333333e-05, 30000000000: 0.00013333333333333334, 3000000: 0.00028333333333333335, 30000000000000000: 5e-05, 3000000000: 8.333333333333333e-05, 300000000000: 8.333333333333333e-05, 3000000000000000: 3.3333333333333335e-05}\n",
      "Agent checkpoint saved at iteration 24000 in 5.\n",
      "Model checkpoint saved at iteration 24000 in 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24101/30001 [13:34:23<4:40:02,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.07111666666666666, 1: 0.6615166666666666, 30: 0.23218333333333332, 3000: 0.0265, 30000: 0.0069166666666666664, 300000: 0.00065, 3000000000000: 8.333333333333333e-05, 300000000: 0.00016666666666666666, 30000000000: 0.00013333333333333334, 30000000: 0.00013333333333333334, 3000000: 0.00028333333333333335, 30000000000000000: 5e-05, 3000000000: 8.333333333333333e-05, 300000000000: 0.00013333333333333334, 3000000000000000: 3.3333333333333335e-05, 30000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 24201/30001 [13:38:49<3:57:30,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.23148333333333335, 300: 0.07085, 1: 0.6627666666666666, 3000: 0.026316666666666665, 300000: 0.0006333333333333333, 30000: 0.0067666666666666665, 3000000000000: 8.333333333333333e-05, 300000000: 0.00016666666666666666, 30000000000: 0.00016666666666666666, 30000000: 0.00013333333333333334, 3000000: 0.0003, 30000000000000000: 5e-05, 3000000000: 8.333333333333333e-05, 300000000000: 0.00015, 3000000000000000: 3.3333333333333335e-05, 30000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 24301/30001 [13:43:14<4:10:58,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.02645, 1: 0.6625, 30: 0.23183333333333334, 300: 0.07075, 30000: 0.006683333333333334, 300000000: 0.00016666666666666666, 30000000000: 0.00018333333333333334, 30000000: 0.00013333333333333334, 3000000000000: 8.333333333333333e-05, 300000: 0.0005833333333333334, 3000000: 0.0003, 30000000000000000: 5e-05, 3000000000: 8.333333333333333e-05, 300000000000: 0.00015, 3000000000000000: 3.3333333333333335e-05, 30000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 24401/30001 [13:47:37<4:01:50,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6630333333333334, 300: 0.07111666666666666, 3000: 0.026483333333333334, 30: 0.23088333333333333, 30000: 0.006666666666666667, 3000000: 0.0003333333333333333, 300000000: 0.00016666666666666666, 30000000: 0.00011666666666666667, 30000000000000000: 6.666666666666667e-05, 3000000000000: 6.666666666666667e-05, 300000: 0.00055, 30000000000: 0.00016666666666666666, 3000000000: 0.0001, 300000000000: 0.00018333333333333334, 3000000000000000: 5e-05, 30000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 24501/30001 [13:51:58<4:06:19,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.66445, 30: 0.23105, 3000: 0.025933333333333333, 300: 0.0703, 30000: 0.006466666666666667, 3000000: 0.0003333333333333333, 3000000000000: 6.666666666666667e-05, 300000: 0.0005833333333333334, 30000000: 0.0001, 30000000000: 0.00016666666666666666, 3000000000: 0.0001, 300000000: 0.00015, 300000000000: 0.00018333333333333334, 30000000000000000: 5e-05, 3000000000000000: 5e-05, 30000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 24601/30001 [13:56:19<4:03:03,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6644166666666667, 30: 0.23098333333333335, 30000000: 0.0001, 3000: 0.025883333333333335, 300: 0.07055, 30000: 0.0062833333333333335, 3000000: 0.00028333333333333335, 30000000000: 0.00018333333333333334, 3000000000: 0.0001, 300000: 0.0006333333333333333, 300000000: 0.00015, 300000000000: 0.0002, 30000000000000000: 5e-05, 3000000000000: 8.333333333333333e-05, 3000000000000000: 5e-05, 30000000000000: 3.3333333333333335e-05, 300000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 24701/30001 [14:00:46<3:54:07,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6622166666666667, 30: 0.23283333333333334, 3000000: 0.0002666666666666667, 300: 0.07108333333333333, 30000: 0.006366666666666666, 3000000000: 0.00013333333333333334, 3000: 0.025583333333333333, 300000: 0.0006833333333333333, 30000000: 8.333333333333333e-05, 300000000: 0.00015, 300000000000: 0.0002, 30000000000000000: 5e-05, 3000000000000: 8.333333333333333e-05, 30000000000: 0.00016666666666666666, 3000000000000000: 5e-05, 30000000000000: 3.3333333333333335e-05, 300000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 24801/30001 [14:05:06<3:50:15,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6623666666666667, 3000: 0.02565, 30: 0.23283333333333334, 300: 0.07085, 30000: 0.0064, 300000: 0.0006666666666666666, 3000000: 0.0002666666666666667, 300000000: 0.00016666666666666666, 300000000000: 0.0002, 30000000000000000: 5e-05, 3000000000000: 8.333333333333333e-05, 30000000: 8.333333333333333e-05, 3000000000: 0.00011666666666666667, 30000000000: 0.00016666666666666666, 3000000000000000: 5e-05, 30000000000000: 3.3333333333333335e-05, 300000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 24901/30001 [14:09:32<3:47:00,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.66285, 30: 0.23231666666666667, 300: 0.0712, 300000000000: 0.0002, 3000: 0.025483333333333334, 30000: 0.00625, 300000: 0.00065, 3000000: 0.0002666666666666667, 300000000: 0.00015, 30000000000000000: 5e-05, 3000000000000: 8.333333333333333e-05, 30000000: 8.333333333333333e-05, 3000000000: 0.00011666666666666667, 30000000000: 0.00018333333333333334, 3000000000000000: 6.666666666666667e-05, 30000000000000: 3.3333333333333335e-05, 300000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25001/30001 [14:13:54<3:45:30,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.23215, 300: 0.07113333333333334, 1: 0.6632833333333333, 3000: 0.025333333333333333, 30000: 0.00625, 30000000000000000: 5e-05, 300000: 0.0006333333333333333, 3000000000000: 8.333333333333333e-05, 300000000: 0.00013333333333333334, 30000000: 8.333333333333333e-05, 300000000000: 0.00016666666666666666, 3000000000: 0.00011666666666666667, 3000000: 0.0002666666666666667, 30000000000: 0.00018333333333333334, 3000000000000000: 8.333333333333333e-05, 30000000000000: 3.3333333333333335e-05, 300000000000000: 1.6666666666666667e-05}\n",
      "Agent checkpoint saved at iteration 25000 in 5.\n",
      "Model checkpoint saved at iteration 25000 in 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 25101/30001 [14:18:16<3:37:54,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.23355, 1: 0.6609166666666667, 300: 0.0722, 3000: 0.0254, 30000000: 8.333333333333333e-05, 30000: 0.0061333333333333335, 300000000000: 0.00016666666666666666, 300000: 0.0006, 3000000000: 0.00015, 3000000: 0.0002666666666666667, 30000000000: 0.00018333333333333334, 300000000: 0.00013333333333333334, 3000000000000000: 8.333333333333333e-05, 30000000000000: 3.3333333333333335e-05, 3000000000000: 6.666666666666667e-05, 30000000000000000: 1.6666666666666667e-05, 300000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 25201/30001 [14:22:39<3:33:41,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6593333333333333, 300: 0.07206666666666667, 30: 0.23501666666666668, 3000: 0.025433333333333332, 30000: 0.006266666666666667, 300000: 0.0005833333333333334, 3000000000: 0.00018333333333333334, 3000000: 0.0003, 30000000000: 0.00018333333333333334, 300000000: 0.00015, 30000000: 0.0001, 300000000000: 0.00015, 3000000000000000: 8.333333333333333e-05, 30000000000000: 3.3333333333333335e-05, 3000000000000: 8.333333333333333e-05, 30000000000000000: 1.6666666666666667e-05, 300000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 25301/30001 [14:27:00<3:25:17,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.658, 30: 0.23545, 300: 0.07251666666666666, 30000: 0.0064333333333333334, 3000: 0.025833333333333333, 300000: 0.0005833333333333334, 3000000000: 0.00015, 30000000: 0.0001, 3000000: 0.0002666666666666667, 30000000000: 0.00015, 300000000: 0.00013333333333333334, 300000000000: 0.00015, 3000000000000000: 8.333333333333333e-05, 30000000000000: 3.3333333333333335e-05, 3000000000000: 8.333333333333333e-05, 30000000000000000: 1.6666666666666667e-05, 300000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 25401/30001 [14:31:21<3:27:46,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.02615, 1: 0.6579333333333334, 30: 0.23511666666666667, 300: 0.07235, 30000: 0.006666666666666667, 3000000: 0.0002666666666666667, 30000000000: 0.00016666666666666666, 300000: 0.0005666666666666667, 300000000: 0.00015, 300000000000: 0.00015, 3000000000000000: 8.333333333333333e-05, 30000000: 8.333333333333333e-05, 3000000000: 0.00016666666666666666, 30000000000000: 3.3333333333333335e-05, 3000000000000: 8.333333333333333e-05, 30000000000000000: 1.6666666666666667e-05, 300000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 25501/30001 [14:35:44<3:21:38,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6593833333333333, 30: 0.234, 3000: 0.026083333333333333, 300: 0.072, 300000: 0.0005666666666666667, 30000: 0.006666666666666667, 3000000: 0.0003, 30000000000: 0.00016666666666666666, 300000000000: 0.00015, 3000000000000000: 8.333333333333333e-05, 30000000: 0.00011666666666666667, 300000000: 0.00015, 3000000000: 0.00016666666666666666, 30000000000000: 3.3333333333333335e-05, 3000000000000: 0.0001, 30000000000000000: 1.6666666666666667e-05, 300000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 25601/30001 [14:40:07<3:07:06,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6641333333333334, 30: 0.23068333333333332, 3000: 0.025766666666666667, 300: 0.07103333333333334, 300000000000: 0.00016666666666666666, 30000: 0.006466666666666667, 3000000000000000: 8.333333333333333e-05, 30000000: 0.00011666666666666667, 300000: 0.00055, 3000000: 0.0002666666666666667, 300000000: 0.00016666666666666666, 3000000000: 0.00016666666666666666, 30000000000: 0.00016666666666666666, 30000000000000: 3.3333333333333335e-05, 3000000000000: 0.00015, 30000000000000000: 1.6666666666666667e-05, 300000000000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 25701/30001 [14:44:25<3:02:36,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.22913333333333333, 300: 0.07061666666666666, 1: 0.6663833333333333, 3000000: 0.00028333333333333335, 30000: 0.006333333333333333, 3000: 0.02555, 30000000: 0.0001, 300000000: 0.00021666666666666666, 300000: 0.00055, 3000000000: 0.00016666666666666666, 30000000000: 0.0002, 3000000000000000: 6.666666666666667e-05, 300000000000: 0.00015, 30000000000000: 3.3333333333333335e-05, 3000000000000: 0.00015, 30000000000000000: 3.3333333333333335e-05, 300000000000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 25801/30001 [14:48:45<2:53:28,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6686333333333333, 30: 0.22696666666666668, 300: 0.07053333333333334, 3000: 0.02565, 30000000000: 0.00021666666666666666, 30000: 0.006266666666666667, 3000000000000000: 6.666666666666667e-05, 300000000: 0.0002, 300000: 0.00055, 300000000000: 0.00015, 30000000000000: 3.3333333333333335e-05, 3000000: 0.00025, 3000000000000: 0.00016666666666666666, 30000000000000000: 3.3333333333333335e-05, 3000000000: 0.00016666666666666666, 300000000000000: 3.3333333333333335e-05, 30000000: 8.333333333333333e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 25901/30001 [14:53:06<2:57:14,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.67155, 30000: 0.0062, 30: 0.22465, 300: 0.07045, 3000: 0.02515, 300000000000: 0.00015, 30000000000000: 3.3333333333333335e-05, 300000: 0.00055, 30000000000: 0.00023333333333333333, 3000000: 0.00028333333333333335, 3000000000000: 0.00016666666666666666, 300000000: 0.00018333333333333334, 3000000000000000: 5e-05, 30000000000000000: 3.3333333333333335e-05, 3000000000: 0.00018333333333333334, 300000000000000: 3.3333333333333335e-05, 30000000: 0.0001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26001/30001 [14:57:28<2:53:33,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.22376666666666667, 1: 0.67315, 300: 0.07005, 30000: 0.0061, 3000: 0.025016666666666666, 300000: 0.0005333333333333334, 3000000: 0.0003, 3000000000000: 0.00016666666666666666, 30000000000: 0.00021666666666666666, 300000000: 0.00018333333333333334, 300000000000: 0.0001, 3000000000000000: 5e-05, 30000000000000000: 3.3333333333333335e-05, 3000000000: 0.00018333333333333334, 30000000000000: 1.6666666666666667e-05, 300000000000000: 3.3333333333333335e-05, 30000000: 0.0001}\n",
      "Agent checkpoint saved at iteration 26000 in 5.\n",
      "Model checkpoint saved at iteration 26000 in 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26101/30001 [15:01:49<2:44:44,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.22338333333333332, 300: 0.06998333333333333, 1: 0.6737166666666666, 300000: 0.0005666666666666667, 3000: 0.024766666666666666, 30000: 0.0061333333333333335, 30000000000: 0.00021666666666666666, 300000000: 0.0002, 300000000000: 0.00011666666666666667, 3000000000000000: 5e-05, 30000000000000000: 3.3333333333333335e-05, 3000000: 0.00028333333333333335, 3000000000: 0.00018333333333333334, 3000000000000: 0.00016666666666666666, 30000000000000: 1.6666666666666667e-05, 300000000000000: 5e-05, 30000000: 0.00013333333333333334}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26201/30001 [15:06:02<2:37:18,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000000000000000: 6.666666666666667e-05, 1: 0.6752666666666667, 30: 0.22231666666666666, 300: 0.06993333333333333, 3000: 0.0244, 30000: 0.00605, 30000000000000000: 3.3333333333333335e-05, 3000000: 0.00028333333333333335, 300000000000: 0.0001, 3000000000: 0.00018333333333333334, 300000: 0.0005666666666666667, 3000000000000: 0.00016666666666666666, 30000000000000: 1.6666666666666667e-05, 300000000000000: 6.666666666666667e-05, 30000000000: 0.0002, 300000000: 0.00021666666666666666, 30000000: 0.00013333333333333334}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 26301/30001 [15:10:21<2:35:39,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6762166666666667, 3000: 0.024033333333333334, 300: 0.06911666666666667, 30: 0.22266666666666668, 30000: 0.005883333333333333, 3000000000000: 0.00016666666666666666, 3000000: 0.00028333333333333335, 30000000000000: 1.6666666666666667e-05, 300000000000000: 6.666666666666667e-05, 300000: 0.0005666666666666667, 300000000000: 8.333333333333333e-05, 30000000000: 0.00021666666666666666, 3000000000: 0.00018333333333333334, 300000000: 0.00028333333333333335, 30000000: 0.00013333333333333334, 3000000000000000: 5e-05, 30000000000000000: 1.6666666666666667e-05, 30000000000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 26401/30001 [15:14:40<2:39:04,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {3000: 0.0234, 300: 0.06973333333333333, 1: 0.6770833333333334, 30: 0.22181666666666666, 300000: 0.0006, 30000: 0.005866666666666667, 3000000000000: 0.00013333333333333334, 300000000000: 8.333333333333333e-05, 30000000000: 0.00023333333333333333, 3000000: 0.00025, 3000000000: 0.00018333333333333334, 300000000: 0.0003, 30000000: 0.00015, 3000000000000000: 6.666666666666667e-05, 300000000000000: 6.666666666666667e-05, 30000000000000000: 1.6666666666666667e-05, 30000000000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 26501/30001 [15:19:05<2:36:45,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.67595, 300: 0.06966666666666667, 30: 0.22273333333333334, 3000: 0.023583333333333335, 30000: 0.005933333333333333, 300000: 0.00055, 3000000000: 0.0002, 30000000000: 0.0002666666666666667, 300000000: 0.00035, 30000000: 0.00015, 3000000: 0.00023333333333333333, 3000000000000000: 6.666666666666667e-05, 3000000000000: 0.00013333333333333334, 300000000000000: 8.333333333333333e-05, 300000000000: 6.666666666666667e-05, 30000000000000000: 1.6666666666666667e-05, 30000000000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 26601/30001 [15:23:20<2:32:07,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.67905, 30: 0.22073333333333334, 300: 0.06883333333333333, 30000: 0.0057, 3000: 0.02355, 30000000: 0.00015, 3000000: 0.0002666666666666667, 3000000000000000: 6.666666666666667e-05, 300000: 0.0005333333333333334, 30000000000: 0.00028333333333333335, 3000000000: 0.00016666666666666666, 300000000: 0.00035, 3000000000000: 0.00013333333333333334, 300000000000000: 8.333333333333333e-05, 300000000000: 6.666666666666667e-05, 30000000000000000: 1.6666666666666667e-05, 30000000000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 26701/30001 [15:27:39<2:25:38,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.67995, 30: 0.22005, 300: 0.0689, 3000: 0.023233333333333335, 30000: 0.0057, 30000000000: 0.00028333333333333335, 300000: 0.0005333333333333334, 3000000000000000: 5e-05, 3000000: 0.00023333333333333333, 3000000000: 0.00016666666666666666, 300000000: 0.00038333333333333334, 30000000: 0.00016666666666666666, 3000000000000: 0.00013333333333333334, 300000000000000: 0.0001, 300000000000: 8.333333333333333e-05, 30000000000000000: 1.6666666666666667e-05, 30000000000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 26801/30001 [15:31:56<2:20:05,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6796, 300: 0.06908333333333333, 30: 0.22008333333333333, 3000: 0.023266666666666668, 30000: 0.005666666666666667, 300000: 0.0005833333333333334, 3000000000000000: 5e-05, 3000000: 0.00025, 3000000000: 0.00016666666666666666, 300000000: 0.0004, 30000000: 0.00018333333333333334, 3000000000000: 0.00015, 30000000000: 0.00028333333333333335, 300000000000000: 0.0001, 300000000000: 0.0001, 30000000000000000: 1.6666666666666667e-05, 30000000000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 26901/30001 [15:36:16<2:11:35,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6809, 30: 0.21951666666666667, 300: 0.06846666666666666, 3000: 0.023133333333333332, 30000: 0.005683333333333334, 3000000000: 0.00016666666666666666, 300000000: 0.0004166666666666667, 3000000: 0.0002666666666666667, 30000000: 0.00018333333333333334, 3000000000000: 0.00015, 300000: 0.0005666666666666667, 30000000000: 0.00028333333333333335, 300000000000000: 0.0001, 300000000000: 0.0001, 30000000000000000: 1.6666666666666667e-05, 3000000000000000: 3.3333333333333335e-05, 30000000000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27001/30001 [15:40:36<2:11:16,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6838833333333333, 3000: 0.02263333333333333, 30: 0.21751666666666666, 300: 0.06801666666666667, 30000: 0.00565, 30000000: 0.00016666666666666666, 3000000000: 0.00013333333333333334, 3000000000000: 0.00015, 3000000: 0.00028333333333333335, 300000: 0.0006166666666666666, 300000000: 0.0004, 30000000000: 0.00028333333333333335, 300000000000000: 0.0001, 300000000000: 0.0001, 30000000000000000: 1.6666666666666667e-05, 3000000000000000: 3.3333333333333335e-05, 30000000000000000000: 1.6666666666666667e-05}\n",
      "Agent checkpoint saved at iteration 27000 in 5.\n",
      "Model checkpoint saved at iteration 27000 in 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27101/30001 [15:44:58<2:02:12,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6854666666666667, 300: 0.0676, 30: 0.21653333333333333, 30000: 0.005416666666666667, 3000: 0.0226, 300000: 0.00065, 300000000: 0.00045, 3000000000: 0.00011666666666666667, 30000000000: 0.00028333333333333335, 3000000000000: 0.00013333333333333334, 3000000: 0.00031666666666666665, 30000000: 0.00015, 300000000000000: 0.00011666666666666667, 300000000000: 0.0001, 30000000000000000: 1.6666666666666667e-05, 3000000000000000: 3.3333333333333335e-05, 30000000000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 27201/30001 [15:49:16<2:02:08,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6882666666666667, 300: 0.06698333333333334, 30: 0.2148, 3000: 0.022216666666666666, 30000: 0.005216666666666666, 3000000000: 0.00013333333333333334, 30000000000: 0.00031666666666666665, 300000: 0.0006833333333333333, 3000000000000: 0.00013333333333333334, 300000000: 0.00045, 3000000: 0.00031666666666666665, 30000000: 0.00016666666666666666, 300000000000000: 0.00011666666666666667, 300000000000: 0.0001, 30000000000000000: 1.6666666666666667e-05, 3000000000000000: 3.3333333333333335e-05, 30000000000000000000: 1.6666666666666667e-05, 300000000000000000: 1.6666666666666667e-05, 30000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 27301/30001 [15:53:33<1:50:00,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6908833333333333, 30: 0.2135, 300: 0.066, 300000: 0.0006833333333333333, 3000: 0.021933333333333332, 30000: 0.005183333333333333, 3000000: 0.0003333333333333333, 30000000: 0.00018333333333333334, 30000000000: 0.0003, 3000000000000: 0.00011666666666666667, 300000000000000: 0.00011666666666666667, 300000000: 0.00045, 300000000000: 0.0001, 30000000000000000: 1.6666666666666667e-05, 3000000000: 0.0001, 3000000000000000: 3.3333333333333335e-05, 30000000000000000000: 1.6666666666666667e-05, 300000000000000000: 1.6666666666666667e-05, 30000000000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 27401/30001 [15:57:49<1:46:48,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6901, 30: 0.21415, 300: 0.06645, 3000: 0.0218, 30000: 0.0051, 300000000000000: 0.00011666666666666667, 300000000: 0.00045, 3000000000000: 0.0001, 300000000000: 0.00011666666666666667, 300000: 0.0007, 3000000: 0.00028333333333333335, 30000000000: 0.0002666666666666667, 30000000000000000: 1.6666666666666667e-05, 3000000000: 0.0001, 30000000: 0.00015, 3000000000000000: 3.3333333333333335e-05, 30000000000000000000: 1.6666666666666667e-05, 300000000000000000: 1.6666666666666667e-05, 30000000000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 27501/30001 [16:02:01<1:46:19,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.067, 30: 0.21628333333333333, 1: 0.6871, 3000: 0.02195, 30000: 0.005333333333333333, 300000: 0.0006666666666666666, 30000000000: 0.00028333333333333335, 300000000: 0.0004333333333333333, 30000000000000000: 1.6666666666666667e-05, 300000000000: 0.0001, 3000000000: 0.0001, 3000000000000: 8.333333333333333e-05, 30000000: 0.00016666666666666666, 3000000: 0.00028333333333333335, 300000000000000: 0.0001, 3000000000000000: 3.3333333333333335e-05, 30000000000000000000: 1.6666666666666667e-05, 300000000000000000: 1.6666666666666667e-05, 30000000000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 27601/30001 [16:06:22<1:43:42,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6846333333333333, 30: 0.21821666666666667, 300: 0.0674, 3000: 0.022116666666666666, 30000: 0.0054, 300000000: 0.0004166666666666667, 3000000000: 0.0001, 3000000000000: 8.333333333333333e-05, 30000000000: 0.0002666666666666667, 30000000: 0.00016666666666666666, 3000000: 0.00028333333333333335, 300000: 0.0006166666666666666, 300000000000: 8.333333333333333e-05, 300000000000000: 0.0001, 3000000000000000: 3.3333333333333335e-05, 30000000000000000000: 1.6666666666666667e-05, 300000000000000000: 1.6666666666666667e-05, 30000000000000: 3.3333333333333335e-05, 30000000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 27701/30001 [16:10:41<1:34:55,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.2196, 1: 0.6837166666666666, 3000: 0.022033333333333332, 300: 0.06678333333333333, 30000: 0.0054666666666666665, 30000000000: 0.00028333333333333335, 3000000: 0.0003, 300000: 0.0006666666666666666, 3000000000: 0.0001, 300000000000: 0.00011666666666666667, 300000000: 0.00045, 30000000: 0.00016666666666666666, 3000000000000: 0.0001, 300000000000000: 0.0001, 3000000000000000: 3.3333333333333335e-05, 30000000000000000000: 1.6666666666666667e-05, 300000000000000000: 1.6666666666666667e-05, 30000000000000: 3.3333333333333335e-05, 30000000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 27801/30001 [16:14:56<1:31:03,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.06723333333333334, 1: 0.68245, 30: 0.22041666666666668, 3000: 0.022166666666666668, 30000: 0.00535, 30000000000: 0.00028333333333333335, 300000: 0.0006666666666666666, 300000000: 0.0005166666666666667, 300000000000: 0.0001, 30000000: 0.00016666666666666666, 3000000000000: 0.0001, 300000000000000: 0.0001, 3000000000000000: 3.3333333333333335e-05, 3000000: 0.00025, 30000000000000000000: 1.6666666666666667e-05, 3000000000: 8.333333333333333e-05, 300000000000000000: 1.6666666666666667e-05, 30000000000000: 3.3333333333333335e-05, 30000000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 27901/30001 [16:19:17<1:31:37,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6810333333333334, 30: 0.22098333333333334, 300: 0.06778333333333333, 30000000: 0.00018333333333333334, 3000: 0.022333333333333334, 30000: 0.00545, 300000: 0.0006333333333333333, 3000000000000: 0.0001, 300000000000000: 0.0001, 3000000000000000: 5e-05, 300000000: 0.0005166666666666667, 3000000: 0.0002666666666666667, 30000000000000000000: 1.6666666666666667e-05, 3000000000: 8.333333333333333e-05, 30000000000: 0.0002666666666666667, 300000000000: 0.00011666666666666667, 300000000000000000: 1.6666666666666667e-05, 30000000000000: 3.3333333333333335e-05, 30000000000000000: 1.6666666666666667e-05, 3000000000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28001/30001 [16:23:36<1:23:06,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.06713333333333334, 1: 0.6813, 30: 0.22126666666666667, 30000: 0.005433333333333333, 3000: 0.022383333333333335, 300000000000000: 8.333333333333333e-05, 300000000: 0.0005333333333333334, 300000: 0.00065, 3000000: 0.0003, 30000000000000000000: 3.3333333333333335e-05, 3000000000: 8.333333333333333e-05, 30000000000: 0.00028333333333333335, 30000000: 0.00016666666666666666, 3000000000000000: 3.3333333333333335e-05, 3000000000000: 0.0001, 300000000000: 0.00013333333333333334, 300000000000000000: 1.6666666666666667e-05, 30000000000000: 3.3333333333333335e-05, 30000000000000000: 1.6666666666666667e-05, 3000000000000000000: 1.6666666666666667e-05}\n",
      "Agent checkpoint saved at iteration 28000 in 5.\n",
      "Model checkpoint saved at iteration 28000 in 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 28101/30001 [16:27:47<1:19:22,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.22185, 1: 0.6810333333333334, 300: 0.06688333333333334, 3000: 0.0224, 30000: 0.005416666666666667, 300000000: 0.0005, 30000000000000000000: 3.3333333333333335e-05, 300000: 0.0006333333333333333, 3000000: 0.00028333333333333335, 3000000000: 8.333333333333333e-05, 30000000000: 0.00028333333333333335, 30000000: 0.00016666666666666666, 300000000000000: 6.666666666666667e-05, 3000000000000000: 3.3333333333333335e-05, 3000000000000: 0.0001, 300000000000: 0.00015, 300000000000000000: 1.6666666666666667e-05, 30000000000000: 3.3333333333333335e-05, 30000000000000000: 1.6666666666666667e-05, 3000000000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 28201/30001 [16:31:47<1:12:18,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6754166666666667, 30: 0.2245, 300: 0.06905, 30000: 0.005666666666666667, 3000: 0.023083333333333334, 300000: 0.0006333333333333333, 3000000000000000: 3.3333333333333335e-05, 30000000000: 0.0002666666666666667, 300000000: 0.0004333333333333333, 3000000000: 6.666666666666667e-05, 300000000000000: 5e-05, 3000000000000: 0.0001, 3000000: 0.0003, 30000000: 0.00015, 300000000000: 0.00015, 300000000000000000: 1.6666666666666667e-05, 30000000000000: 3.3333333333333335e-05, 30000000000000000: 1.6666666666666667e-05, 3000000000000000000: 1.6666666666666667e-05, 30000000000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 28301/30001 [16:36:03<1:10:29,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6730166666666667, 30: 0.22551666666666667, 300: 0.06976666666666667, 30000: 0.0057, 3000: 0.02365, 300000000: 0.00046666666666666666, 30000000000: 0.00028333333333333335, 3000000000: 6.666666666666667e-05, 300000000000000: 5e-05, 3000000000000: 0.00013333333333333334, 3000000: 0.0003333333333333333, 300000: 0.0006, 30000000: 0.00015, 300000000000: 0.00015, 300000000000000000: 1.6666666666666667e-05, 30000000000000: 3.3333333333333335e-05, 30000000000000000: 1.6666666666666667e-05, 3000000000000000000: 1.6666666666666667e-05, 3000000000000000: 1.6666666666666667e-05, 30000000000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 28401/30001 [16:40:13<1:09:14,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.0704, 1: 0.6724166666666667, 30: 0.22556666666666667, 3000: 0.023683333333333334, 300000: 0.0006166666666666666, 30000: 0.0056, 30000000000: 0.00025, 3000000: 0.00036666666666666667, 300000000: 0.0004166666666666667, 30000000: 0.00015, 300000000000000: 3.3333333333333335e-05, 300000000000: 0.00016666666666666666, 3000000000000: 0.00015, 3000000000: 5e-05, 300000000000000000: 1.6666666666666667e-05, 30000000000000: 5e-05, 30000000000000000: 1.6666666666666667e-05, 3000000000000000000: 1.6666666666666667e-05, 3000000000000000: 1.6666666666666667e-05, 30000000000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 28501/30001 [16:44:29<1:03:24,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6726, 30: 0.22593333333333335, 3000: 0.02351666666666667, 300: 0.06993333333333333, 30000: 0.005716666666666667, 30000000: 0.00016666666666666666, 300000000000000: 3.3333333333333335e-05, 300000: 0.0006, 300000000000: 0.00016666666666666666, 300000000: 0.0004333333333333333, 3000000000000: 0.00015, 30000000000: 0.00021666666666666666, 3000000: 0.00035, 3000000000: 5e-05, 300000000000000000: 1.6666666666666667e-05, 30000000000000: 5e-05, 30000000000000000: 1.6666666666666667e-05, 3000000000000000000: 1.6666666666666667e-05, 3000000000000000: 1.6666666666666667e-05, 30000000000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 28601/30001 [16:48:47<58:22,  2.50s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6717333333333333, 300: 0.06983333333333333, 30: 0.22691666666666666, 3000: 0.023416666666666665, 30000: 0.005833333333333334, 30000000000: 0.00021666666666666666, 300000: 0.0006, 300000000000: 0.00015, 30000000: 0.00013333333333333334, 300000000: 0.0004166666666666667, 3000000: 0.00036666666666666667, 3000000000: 8.333333333333333e-05, 300000000000000: 1.6666666666666667e-05, 300000000000000000: 1.6666666666666667e-05, 30000000000000: 5e-05, 3000000000000: 0.00015, 30000000000000000: 1.6666666666666667e-05, 3000000000000000000: 1.6666666666666667e-05, 3000000000000000: 1.6666666666666667e-05, 30000000000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 28701/30001 [16:53:04<56:16,  2.60s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6727666666666666, 30: 0.22628333333333334, 30000: 0.005883333333333333, 300: 0.06955, 3000: 0.023233333333333335, 300000000: 0.0004166666666666667, 3000000: 0.00035, 300000: 0.0005666666666666667, 3000000000: 0.00011666666666666667, 300000000000000: 3.3333333333333335e-05, 30000000000: 0.0002, 30000000: 0.00013333333333333334, 300000000000000000: 1.6666666666666667e-05, 30000000000000: 6.666666666666667e-05, 3000000000000: 0.00015, 300000000000: 0.00015, 30000000000000000: 1.6666666666666667e-05, 3000000000000000000: 3.3333333333333335e-05, 3000000000000000: 1.6666666666666667e-05, 30000000000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 28801/30001 [16:57:23<51:27,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.22646666666666668, 1: 0.6715166666666667, 300: 0.07011666666666666, 30000: 0.0059833333333333336, 3000: 0.0236, 300000000: 0.0004166666666666667, 300000: 0.0006, 3000000: 0.0003333333333333333, 3000000000: 0.00011666666666666667, 300000000000000: 3.3333333333333335e-05, 30000000000: 0.00021666666666666666, 30000000: 0.00013333333333333334, 300000000000000000: 1.6666666666666667e-05, 30000000000000: 6.666666666666667e-05, 3000000000000: 0.00015, 300000000000: 0.00015, 30000000000000000: 1.6666666666666667e-05, 3000000000000000000: 3.3333333333333335e-05, 3000000000000000: 1.6666666666666667e-05, 30000000000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 28901/30001 [17:01:41<47:21,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.06976666666666667, 30000: 0.006016666666666667, 1: 0.67155, 30: 0.22655, 3000: 0.02385, 300000: 0.0006, 3000000: 0.00031666666666666665, 300000000000000: 3.3333333333333335e-05, 300000000: 0.00038333333333333334, 30000000000: 0.00021666666666666666, 30000000: 0.00013333333333333334, 300000000000000000: 1.6666666666666667e-05, 3000000000: 0.00011666666666666667, 30000000000000: 6.666666666666667e-05, 3000000000000: 0.00015, 300000000000: 0.00015, 30000000000000000: 1.6666666666666667e-05, 3000000000000000000: 3.3333333333333335e-05, 3000000000000000: 1.6666666666666667e-05, 30000000000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29001/30001 [17:06:04<43:51,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6707, 30: 0.22706666666666667, 300: 0.0701, 30000: 0.005916666666666666, 3000: 0.02405, 3000000000: 0.00011666666666666667, 300000: 0.0005833333333333334, 30000000000: 0.00021666666666666666, 30000000000000: 6.666666666666667e-05, 30000000: 0.00011666666666666667, 300000000: 0.00036666666666666667, 3000000: 0.0002666666666666667, 3000000000000: 0.00015, 300000000000: 0.00016666666666666666, 30000000000000000: 1.6666666666666667e-05, 3000000000000000000: 3.3333333333333335e-05, 3000000000000000: 1.6666666666666667e-05, 30000000000000000000: 1.6666666666666667e-05, 300000000000000: 3.3333333333333335e-05}\n",
      "Agent checkpoint saved at iteration 29000 in 5.\n",
      "Model checkpoint saved at iteration 29000 in 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29101/30001 [17:10:30<42:17,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6703, 30: 0.22711666666666666, 300: 0.07041666666666667, 3000: 0.02415, 30000: 0.00595, 30000000000000: 5e-05, 300000000: 0.00038333333333333334, 3000000: 0.0002666666666666667, 3000000000000: 0.00015, 300000: 0.0005166666666666667, 300000000000: 0.00016666666666666666, 30000000000: 0.00021666666666666666, 30000000: 0.0001, 30000000000000000: 1.6666666666666667e-05, 3000000000: 0.0001, 3000000000000000000: 3.3333333333333335e-05, 3000000000000000: 1.6666666666666667e-05, 30000000000000000000: 1.6666666666666667e-05, 300000000000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29201/30001 [17:14:53<34:23,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6698666666666667, 30: 0.22751666666666667, 300: 0.07046666666666666, 3000000000000: 0.00015, 3000: 0.024366666666666665, 30000: 0.005666666666666667, 300000: 0.0005333333333333334, 300000000000: 0.00018333333333333334, 3000000: 0.00025, 300000000: 0.0004, 30000000000: 0.00021666666666666666, 30000000: 0.00011666666666666667, 30000000000000000: 1.6666666666666667e-05, 3000000000: 0.00011666666666666667, 3000000000000000000: 3.3333333333333335e-05, 3000000000000000: 1.6666666666666667e-05, 30000000000000000000: 1.6666666666666667e-05, 30000000000000: 3.3333333333333335e-05, 300000000000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 29301/30001 [17:19:12<30:31,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.22716666666666666, 300: 0.07043333333333333, 1: 0.6700833333333334, 3000: 0.024433333333333335, 300000000: 0.0004166666666666667, 30000: 0.005683333333333334, 30000000000: 0.00025, 30000000: 0.00013333333333333334, 300000: 0.00055, 30000000000000000: 3.3333333333333335e-05, 3000000: 0.00025, 3000000000000: 0.00013333333333333334, 300000000000: 0.00016666666666666666, 3000000000: 0.00013333333333333334, 3000000000000000000: 3.3333333333333335e-05, 3000000000000000: 1.6666666666666667e-05, 30000000000000000000: 1.6666666666666667e-05, 30000000000000: 3.3333333333333335e-05, 300000000000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 29401/30001 [17:23:38<25:03,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30: 0.22703333333333334, 1: 0.6704333333333333, 300: 0.07018333333333333, 3000: 0.02445, 30000: 0.005566666666666667, 300000000: 0.00046666666666666666, 300000: 0.0005833333333333334, 30000000000000000: 3.3333333333333335e-05, 30000000000: 0.00023333333333333333, 3000000: 0.0002666666666666667, 30000000: 0.00013333333333333334, 3000000000000: 0.00013333333333333334, 300000000000: 0.00018333333333333334, 3000000000: 0.00015, 3000000000000000000: 3.3333333333333335e-05, 3000000000000000: 1.6666666666666667e-05, 30000000000000000000: 1.6666666666666667e-05, 30000000000000: 3.3333333333333335e-05, 300000000000000: 5e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 29501/30001 [17:27:58<21:28,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {30000: 0.005533333333333334, 30: 0.2269, 1: 0.6707166666666666, 3000: 0.024516666666666666, 300: 0.06996666666666666, 300000: 0.00055, 3000000000000: 0.00015, 30000000000: 0.0003, 300000000: 0.00046666666666666666, 300000000000: 0.00018333333333333334, 3000000000: 0.00015, 3000000: 0.0002666666666666667, 3000000000000000000: 3.3333333333333335e-05, 30000000: 0.00011666666666666667, 3000000000000000: 1.6666666666666667e-05, 30000000000000000000: 1.6666666666666667e-05, 30000000000000: 5e-05, 300000000000000: 5e-05, 30000000000000000: 1.6666666666666667e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 29601/30001 [17:32:01<13:23,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {300: 0.07051666666666667, 1: 0.66735, 30: 0.22995, 3000: 0.024283333333333334, 300000000: 0.0004166666666666667, 300000: 0.0006, 30000: 0.005483333333333333, 30000000000: 0.00031666666666666665, 3000000: 0.00028333333333333335, 300000000000: 0.00016666666666666666, 3000000000000000000: 3.3333333333333335e-05, 30000000: 0.00013333333333333334, 3000000000000000: 1.6666666666666667e-05, 30000000000000000000: 1.6666666666666667e-05, 3000000000000: 0.00011666666666666667, 30000000000000: 5e-05, 3000000000: 0.00016666666666666666, 300000000000000: 6.666666666666667e-05, 30000000000000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 29701/30001 [17:35:43<12:00,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6609, 30: 0.23595, 3000: 0.023583333333333335, 300: 0.07196666666666666, 300000000000: 0.00016666666666666666, 3000000000000000000: 3.3333333333333335e-05, 30000: 0.005216666666666666, 30000000: 0.00013333333333333334, 3000000000000000: 1.6666666666666667e-05, 300000: 0.0005833333333333334, 30000000000000000000: 1.6666666666666667e-05, 300000000: 0.00035, 30000000000: 0.0003, 3000000000000: 0.00015, 3000000: 0.0003, 30000000000000: 5e-05, 3000000000: 0.00018333333333333334, 300000000000000: 6.666666666666667e-05, 30000000000000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 29801/30001 [17:39:41<07:59,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6578666666666667, 30: 0.23996666666666666, 300: 0.07173333333333333, 3000: 0.022983333333333335, 30000: 0.005033333333333333, 300000: 0.0006, 30000000000000000000: 1.6666666666666667e-05, 300000000: 0.00038333333333333334, 30000000000: 0.0003, 3000000000000: 0.00018333333333333334, 30000000: 0.00011666666666666667, 3000000: 0.00031666666666666665, 300000000000: 0.00013333333333333334, 30000000000000: 5e-05, 3000000000: 0.0002, 3000000000000000000: 1.6666666666666667e-05, 300000000000000: 6.666666666666667e-05, 30000000000000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 29901/30001 [17:43:39<03:53,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6519, 30: 0.24515, 300: 0.07281666666666667, 3000: 0.0228, 30000: 0.004916666666666666, 3000000: 0.0003333333333333333, 300000: 0.0005333333333333334, 3000000000000: 0.00018333333333333334, 300000000: 0.00036666666666666667, 30000000000: 0.00031666666666666665, 300000000000: 0.00015, 30000000000000: 5e-05, 30000000: 0.00011666666666666667, 3000000000: 0.00025, 3000000000000000000: 1.6666666666666667e-05, 300000000000000: 6.666666666666667e-05, 30000000000000000: 3.3333333333333335e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30001/30001 [17:47:40<00:00,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Reward Distribution: {1: 0.6480833333333333, 30: 0.2491, 300: 0.07293333333333334, 3000: 0.022333333333333334, 30000: 0.004783333333333333, 300000: 0.0005666666666666667, 3000000: 0.00038333333333333334, 3000000000000: 0.0002, 300000000: 0.00046666666666666666, 30000000000: 0.00036666666666666667, 300000000000: 0.00018333333333333334, 30000000000000: 6.666666666666667e-05, 30000000: 0.00015, 3000000000: 0.0002666666666666667, 3000000000000000000: 1.6666666666666667e-05, 300000000000000: 6.666666666666667e-05, 30000000000000000: 3.3333333333333335e-05}\n",
      "Agent checkpoint saved at iteration 30000 in 5.\n",
      "Model checkpoint saved at iteration 30000 in 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    save_path = 'results-v3'\n",
    "    device = 'cpu'\n",
    "    progress = True  \n",
    "    method = 'flownet'\n",
    "    learning_rate = 5e-4\n",
    "    opt = 'adam'\n",
    "    adam_beta1 = 0.9\n",
    "    adam_beta2 = 0.999\n",
    "    momentum = 0.9  # SGD with momentum\n",
    "    mbsize = 8  # number of parallel environments (trajectories) are collected by one agent (One Agent's model is shared in Many Environments). \n",
    "    train_to_sample_ratio = 1.0  # determines how many times the agent should update its model (train) for each set of data it collects from the environment. \n",
    "    clip_grad_norm = 0.\n",
    "    n_hid = 256  # number of hidden units in each hidden layer\n",
    "    n_layers = 3\n",
    "    n_train_steps = 25000 \n",
    "    num_empirical_loss = 50000  # number of samples used to compute the empirical distribution loss during evaluation.\n",
    "    \n",
    "    \n",
    "    # Env\n",
    "    func = 'oscillator'\n",
    "    horizon = 12  # 4*3 \n",
    "    nnode = 7\n",
    "    ndim = nnode*nnode \n",
    "    \n",
    "    # Flownet\n",
    "    bootstrap_tau = 0.0  # no bootstrapping,target network isn't being updated gradually but possibly replaced entirely at some point.\n",
    "    replay_strategy = 'top_k'  # 'top_k' or 'none'\n",
    "    replay_sample_size = 5  # number of experiences to sample from the replay buffer at each update step.\n",
    "    replay_buf_size = 100  #  size of the replay buffer, which stores past experiences for the agent to learn from.\n",
    "    log_reg_c = 2.5e-5\n",
    "\n",
    "\n",
    "\n",
    "args = Args()\n",
    "torch.set_num_threads(200)\n",
    "main(args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "960032"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_visited_done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa = [1, 2, 3]\n",
    "aaa[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
